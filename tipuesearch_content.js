var tipuesearch = {"pages":[{"title":"Fixing Vagrant and VMware Fusion","text":"For some reason Vagrant is sometimes unable to start the virtual machine and aborts with an error message like: Some of the defined forwarded ports would collide with existing forwarded ports on VMware network devices. This can be due to existing Vagrant-managed VMware machines, or due to manually configured port forwarding with VMware. Please fix the following port collisions and try again: 2222 If you run into that problem there are a few things that might help you fix them. You can for example shut down your vagrant machine and remove it from the virtual machine \"Virtual Machines\" sidebar in the Fusion UI . If you're lucky that will already solve your problem. Some other time the following series of commands seems to help solve the issue at hand: $#> vagrant halt && \\ sudo rm -f /opt/vagrant-vmware-desktop/settings/nat.json && \\ sudo killall vagrant-vmware-utility && \\ vagrant up If that doesn't solve you're problem, you can try a combination of both approaches. If this doesn't work you have to continue googling ;)","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/fixing-vagrant-and-vmware-fusion","loc":"https://datapile.coffeecrew.org/fixing-vagrant-and-vmware-fusion"},{"title":"How To Remove PDF Write Protection","text":"Some PDFs you download are write protected. This is especially annoying if you do like to mark up the PDF in a utility like e.g. DEVONthink . It is not even possible to simply highlight something as long as the PDF is write protected. Luckily the problem can be solved with a little command line application called qpdf . Installation There are multiple ways to install the software. You can either use the package manager of your operating system or you can use Docker . This will allow you to quickly use the command and discard the whole execution environment if you no longer need it. Homebrew I'm on a Mac and if you have Homebrew installed, you can execute brew install qpdf in your terminal application. This will download and install the qpdf command line tool that you can use to remove the PDF write protection. Note I'm running the following version: #$> qpdf --version qpdf version 10.0.1 Run qpdf --copyright to see copyright and license information. Keep this in mind if a feature is not available or does not work. If you're not on a Mac you need to use the package manager of your operating system to install the application. You can use the utility like so: #$> cd folder-with-pdf #$> qpdf --replace-input my.pdf Docker If you are already using Docker then why not employ a container to get the job done. The container I am using is pretty heavyweight if you just need to use the little qpdf utility and you may want to use a smaller container. However, if you're additionally documenting stuff with Sphinx or use Pelican to write your blog, the heavyweight container might be a good choice for you anyway. You can use the custom Sphinx container as follows: #$> cd folder-with-pdf #$> docker run --rm -it -v $(pwd):/docs authsec/sphinx qpdf --replace-input my.pdf Note If you're on Windows, the current working directory needs to be specified with ${PWD} .","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/how-to-remove-pdf-write-protection","loc":"https://datapile.coffeecrew.org/how-to-remove-pdf-write-protection"},{"title":"How To Start A Consul Docker Image","text":"If you quickly have to start a Consul docker image you can use the following command: docker run -p 8400:8400 -p 127.0.0.1:8500:8500 -p 8600:8600/udp -h node1 consul agent -dev -client 0.0.0.0 This is especially useful for development purposes and quick tests and should not be used in a productive environment.","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/how-to-start-a-consul-docker-image","loc":"https://datapile.coffeecrew.org/how-to-start-a-consul-docker-image"},{"title":"Upload Maven Artifacts Into Nexus 3","text":"Sometimes you need to upload an artifact into Nexus. With Nexus 2 this was very easy if you had filesystem access or access to the Web UI . In Nexus 3 you are no longer able to access the filesystem and do not have a UI to upload your artifacts. This is why you have to do it using the mvn CLI . If you have some strangely proxied system where you have ssh access to the machine running Nexus you can also use SSH port forwarding if you are unable to reach the machine directly otherwise. You need a configuration like this where the user has permission to deploy into your repository. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <settings xmlns= \"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd\" > <servers> <server> <!-- Link this id here to the repo ID in the mirror section --> <id> repo </id> <username> deployment </username> <password> password </password> </server> </servers> </settings> Get the Gist here ! If that is out of the way you can use the CLI to upload the artifact like so: Please note that in this case also a different configuration file is used to upload the artifact, to avoid working with the deployment user for normal builds where you want the user only to have read permission. mvn -s ~/.m2/settings.xml.upload deploy:deploy-file \\ -DgroupId = org.wildfly \\ -DartifactId = wildfly-dist \\ -Dversion = 10 .0.0.Final \\ -DgeneratePom = true \\ -Dpackaging = tar.gz \\ -DrepositoryId = repo \\ -Durl = http://repo.example.com/repository/thirdparty \\ -Dfile = wildfly-10.0.0.Final.tar.gz","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/upload-maven-artifacts-into-nexus-3","loc":"https://datapile.coffeecrew.org/upload-maven-artifacts-into-nexus-3"},{"title":"Programmatically Start A JSF Flow","text":"Note This was tested with Wildfly 10.0.0.Final, Mojarra 2.2.12 and Java JDK 1.8.0_51 There are situations where you can not start a JSF (2.2) flow in the usual way by simply redirecting to the flow's start page from your button action. This is for example the case when you want to start a JSF flow from e.g. a view action method. In this case it is not sufficient to simple return the view name of the flow as this will not just start it. To properly start the flow you need to first tell the flow handler that you are now transitioning into a flow. You can do this with the following code: FacesContext context = FacesContext . getCurrentInstance (); FlowHandler handler = context . getApplication (). getFlowHandler (); handler . transition ( context , null , handler . getFlow ( context , \"\" , FLOW_NAME ), null , \"\" ); return FLOW_NAME ; If done like this, that flow should start as expected. However, if you don't set up the FlowHandler.transition properly you will end up with the following error: WELD-001303: No active contexts for scope type javax.faces.flow.FlowScoped Note You need to reach the page running the view action through a GET request. So using the normal h:commandButton will not work in this case as this issues a POST request (except you add ?faces-redirect=true to your action parameter of course). The full source for this example can be found here .","tags":"Programming","url":"https://datapile.coffeecrew.org/programmatically-start-a-jsf-flow","loc":"https://datapile.coffeecrew.org/programmatically-start-a-jsf-flow"},{"title":"Back To QNAP","text":"Sometimes you may want to backup/synchronize data from a remote server to your local QNAP server. This can be done fairly easily and efficiently using the already installed rsync command. Note You need to have set up a passwordless SSH login from your QNAP to your remote host for the below script to work. In addition the script below will send an eMail once it finishes it's run. To get the script going on your machine, simply adapt the variables to point to your local directories and supply a valid eMail address (can be the same for FROM and TO ). As any operating system upgrade will otherwise delete your backup script you need to place it onto the share disk itself, as this will prevent the script of being deleted during an upgrade operation (I suggest stuffing it into a Gist on Github as well ;)). I suggest putting the script in the following location if you have set up a RAID 5 array (the location may be slightly different for you setup) /share/MD0_DATA . #!/bin/sh # Script to periodically synchronize a remote directory with your # local QNAP storage. # Source folders/user on remote machine BACKUP_SOURCE_USER = \"backup-user\" BACKUP_SOURCE_HOST = \"backuphost.example.com\" BACKUP_SOURCE_FOLDER = \"/backup/subdir\" # Directory to save the remote backup locally BACKUP_SINK_FOLDER = \"/share/MD0_DATA/Qmultimedia/backup-dir\" # For grepping the available space BACKUP_SHARE_MOUNT_POINT = \"/share/MD0_DATA\" SUBJ_PREFIX = \"[RSYNC BACKUP]\" SUBJECT_FAIL = \" ${ SUBJ_PREFIX } Synchronization unsuccessful!\" SUBJECT_SUCCESS = \" ${ SUBJ_PREFIX } Synchronization successful!\" MAIL_TO = \"hansi@example.com\" MAIL_FROM = \"hansi-machine@example.com\" MSG_CONTENT_FILE = \"/tmp/email_body.txt\" RSYNC_CONTENT_FILE = \"/tmp/rsyncContent.txt\" # Sends a mail message # $1 = subject # $2 = to # $3 = from # $4 = msg send_mail () { local tmpfile = \"/tmp/sendmail.tmp\" /bin/echo -e \"Subject: $1 \\r\" > \" $tmpfile \" /bin/echo -e \"To: $2 \\r\" >> \" $tmpfile \" /bin/echo -e \"From: $3 \\r\" >> \" $tmpfile \" /bin/echo -e \"\\r\" >> \" $tmpfile \" if [ -f \" $4 \" ] ; then cat \" $4 \" >> \" $tmpfile \" /bin/echo -e \"\\r\\n\" >> \" $tmpfile \" else /bin/echo -e \" $4 \\r\\n\" >> \" $tmpfile \" fi /usr/sbin/sendmail -t < \" $tmpfile \" rm $tmpfile } /bin/echo -e \"Backup started at: $( date ) \\n\" > ${ MSG_CONTENT_FILE } /bin/echo \"Space available on backup disk (before backup)\" >> ${ MSG_CONTENT_FILE } /bin/echo \" $( df -h | head -n1 ) \" >> ${ MSG_CONTENT_FILE } /bin/echo \" $( df -h | grep ${ BACKUP_SHARE_MOUNT_POINT } ) \" >> ${ MSG_CONTENT_FILE } /bin/echo -e \"\\n\" >> ${ MSG_CONTENT_FILE } /bin/echo -e \"The following output was produced by the rsync command:\\n\" > ${ RSYNC_CONTENT_FILE } /usr/bin/rsync -azhv ${ BACKUP_SOURCE_USER } @ ${ BACKUP_SOURCE_HOST } : ${ BACKUP_SOURCE_FOLDER } ${ BACKUP_SINK_FOLDER } >> ${ RSYNC_CONTENT_FILE } if [ $? -eq 0 ] then SUBJECT = ${ SUBJECT_SUCCESS } else SUBJECT = ${ SUBJECT_FAIL } fi /bin/echo -e \"Backup ended at: $( date ) \\n\" >> ${ MSG_CONTENT_FILE } /bin/echo \"Space available on backup disk (after backup)\" >> ${ MSG_CONTENT_FILE } /bin/echo \" $( df -h | head -n1 ) \" >> ${ MSG_CONTENT_FILE } /bin/echo \" $( df -h | grep ${ BACKUP_SHARE_MOUNT_POINT } ) \" >> ${ MSG_CONTENT_FILE } /bin/echo -e \"\\n\" >> ${ MSG_CONTENT_FILE } /bin/cat ${ RSYNC_CONTENT_FILE } >> ${ MSG_CONTENT_FILE } send_mail \" ${ SUBJECT } \" \" ${ MAIL_TO } \" \" ${ MAIL_FROM } \" ${ MSG_CONTENT_FILE } Get the Gist here ! Executing a Daily Backup Once the script is in it's place you need to configure a cron job so it will be executed let's say once a day at 5 AM . To do so simply type crontab -e into your terminal as admin user and add a line like this at the end of the file. 0 5 * * * /share/MD0_DATA/backupRemoteDirToQnap.sh There you have it, nice and shiny backup.","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/back-to-qnap","loc":"https://datapile.coffeecrew.org/back-to-qnap"},{"title":"How To Setup Hovercraft On Mac OS","text":"If you want to setup hovercraft for creating presentations on your Mac, the following steps may help if you already have MacPorts installed. At first install python if you haven't already: $# > sudo port install python33 py33-pip As you'll run into problems, you have to export the language for the next command to run successfully. So add these two lines to your ~/.bash_profile export LC_ALL = en_US.UTF-8 export LANG = en_US.UTF-8 And while we're at it, add the following path to your PATH variable as well, so you can later access the hovercraft command directly. $# > /opt/local/Library/Frameworks/Python.framework/Versions/3.3/bin Your path then looks something like this: $# > export PATH = \"/opt/local/bin:/opt/local/sbin:/opt/local/Library/Frameworks/Python.framework/Versions/3.3/bin: $PATH \" Now you can finally install hovercraft like this: $# > sudo -H pip install hovercraft Happy hovercrafting!","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/how-to-setup-hovercraft-on-mac-os","loc":"https://datapile.coffeecrew.org/how-to-setup-hovercraft-on-mac-os"},{"title":"Quickly Rename a Bunch Of Files With Bash","text":"Sometimes you might feel the need to rename a bunch of files from one file extension to another. This can easily be done with built in shell functions. To quickly rename a bunch of file endings from say for example *.markdown to *.md you simply can execute the following ( bash ) command. for i in *.markdown ; do mv $i \" ${ i %.markdown } .md\" ; done","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/quickly-rename-a-bunch-of-files-with-bash","loc":"https://datapile.coffeecrew.org/quickly-rename-a-bunch-of-files-with-bash"},{"title":"Setup A Local DNS Server For Development","text":"Note This was implemented and tested with Mac OS 10.10.4 and Dnsmasq 2.75 When you develop a web site or when you want to address multiple virtual machines by name on your local machine, you need to find a solution to implement this. You can either input all your host names into your local /etc/resolv.conf which may not result in a managable scenario after some time, or you can just install Dnsmasq which is a local DNS responder that allows you to manage your own custom domain or extend the dns domain name space of another service. You can install Dnsmasq from ports or probably homebrew if you're on a Mac or get it from your local packet manager on your favourite Linux distribution. After the installation just make sure that you are pointing you operating systems DNS resolution to your local host instance. To resolve the usual internet domains via dnsmasq as well be sure to include your official DNS server in the configration. The Dnsmasq configuration file can be found at /opt/local/etc/dnsmasq.conf if you installed from ports. My configuration file is somewhat along these lines. You probably want to use sudo to change this file for editing like for example so sudo vim /opt/local/etc/dnsmasq.conf . resolv-file=/etc/resolv.conf # My local IP address server=192.168.221.1 # Both are googles DNS servers server=8.8.8.8 server=8.8.4.4 # here go the IP addresses you want to remap or setup as new address=/alpha1.cluster.local.domain/172.16.232.135 address=/red.alpha1.cluster.local.domain/172.16.232.141 address=/black.alpha1.cluster.local.domain/172.16.232.141 address=/green.alpha2.cluster.local.domain/172.16.232.132 After you have changed the configuration you probably want to flush the DNS cache and reload the service by issuing the following commands: sudo port unload dnsmasq && \\ sudo killall -HUP mDNSResponder && \\ sudo port load dnsmasq","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/setup-a-local-dns-server-for-development","loc":"https://datapile.coffeecrew.org/setup-a-local-dns-server-for-development"},{"title":"Have a ReST Endpoint Catch All","text":"If you need a ReST endpoint which returns kind of a default page when a client accesses a unmapped path, you need an implementation like the one shown below. Index.java @ApplicationScoped @Path ( \"/\" ) @Produces ( MediaType . TEXT_HTML ) public class Index { @GET @Path ( \"/{any : .*}\" ) public Response root () { return Response . ok (). entity ( \"<!DOCTYPE html>\\n\" + \"<html>\\n\" + \" <head>\\n\" + \" <title>Response</title>\\n\" + \" </head>\\n\" + \" <body>\\n\" + \" <h1>Catch All Response</h1>\\n\" + \" </body>\\n\" + \"</html>\" ). build (); } }","tags":"Programming","url":"https://datapile.coffeecrew.org/have-a-rest-endpoint-catch-all","loc":"https://datapile.coffeecrew.org/have-a-rest-endpoint-catch-all"},{"title":"Accessing Basic Auth Protected Maven Repositories","text":"When you try to access a basic auth protected maven repository you might actually already run into all sorts of weird errors, but now trying a basic auth protected maven repository during a Arquillian build when it is creating the deployment. You migh have figured out the first part of accessing the maven repositoryis setting a Authorization header and your configuration looks something like this (the encoded username is test and the password is s3cur3 ) : <servers> <server> <!-- Link this id here to the repo ID in the mirror section --> <id> repo </id> <configuration> <httpHeaders> <property> <name> Authorization </name> <value> Basic dGVzdDpzM2N1cjM= </value> </property> </httpHeaders> </configuration> </server> </servers> What you now just need to do on top of that is add the username and password to your settings.xml configuration file like so. <servers> <server> <!-- Link this id here to the repo ID in the mirror section --> <id> repo </id> <username> test </username> <password> s3cur3 </password> <configuration> <httpHeaders> <property> <name> Authorization </name> <value> Basic dGVzdDpzM2N1cjM= </value> </property> </httpHeaders> </configuration> </server> </servers> Get the Gist here ! You especially need add values for these two if you run into the following exception. java . lang . RuntimeException : Could not invoke deployment method : public static org . jboss . shrinkwrap . api . Archive org . coffeecrew . Test . createDeployment () at org . eclipse . aether . internal . impl . DefaultArtifactResolver . resolve ( DefaultArtifactResolver . java : 459 ) at org . eclipse . aether . internal . impl . DefaultArtifactResolver . resolveArtifacts ( DefaultArtifactResolver . java : 262 ) at org . eclipse . aether . internal . impl . DefaultArtifactResolver . resolveArtifact ( DefaultArtifactResolver . java : 239 ) at org . apache . maven . repository . internal . DefaultArtifactDescriptorReader . loadPom ( DefaultArtifactDescriptorReader . java : 320 ) at org . apache . maven . repository . internal . DefaultArtifactDescriptorReader . readArtifactDescriptor ( DefaultArtifactDescriptorReader . java : 217 ) at org . eclipse . aether . internal . impl . DefaultDependencyCollector . process ( DefaultDependencyCollector . java : 461 ) at org . eclipse . aether . internal . impl . DefaultDependencyCollector . process ( DefaultDependencyCollector . java : 573 ) at org . eclipse . aether . internal . impl . DefaultDependencyCollector . collectDependencies ( DefaultDependencyCollector . java : 261 ) at org . eclipse . aether . internal . impl . DefaultRepositorySystem . resolveDependencies ( DefaultRepositorySystem . java : 342 ) at org . jboss . shrinkwrap . resolver . impl . maven . bootstrap . MavenRepositorySystem . resolveDependencies ( MavenRepositorySystem . java : 120 ) at org . jboss . shrinkwrap . resolver . impl . maven . MavenWorkingSessionImpl . resolveDependencies ( MavenWorkingSessionImpl . java : 266 ) at org . jboss . shrinkwrap . resolver . impl . maven . MavenStrategyStageBaseImpl . using ( MavenStrategyStageBaseImpl . java : 71 ) at org . jboss . shrinkwrap . resolver . impl . maven . MavenStrategyStageBaseImpl . using ( MavenStrategyStageBaseImpl . java : 40 ) Caused by : org . eclipse . aether . transfer . ArtifactTransferException : Could not transfer artifact org . slf4j : slf4j - log4j12 : pom : 1.4.3 from / to repo ( https : //repo.protected.example.com/content/groups/internal/): Access denied to: https://repo.protected.example.com/content/groups/internal/org/slf4j/slf4j-log4j12/1.4.3/slf4j-log4j12-1.4.3.pom at org . eclipse . aether . connector . wagon . WagonRepositoryConnector$6 . wrap ( WagonRepositoryConnector . java : 1016 ) at org . eclipse . aether . connector . wagon . WagonRepositoryConnector$6 . wrap ( WagonRepositoryConnector . java : 1004 ) at org . eclipse . aether . connector . wagon . WagonRepositoryConnector$GetTask . run ( WagonRepositoryConnector . java : 725 ) at org . eclipse . aether . util . concurrency . RunnableErrorForwarder$1 . run ( RunnableErrorForwarder . java : 67 ) at java . util . concurrent . ThreadPoolExecutor . runWorker ( ThreadPoolExecutor . java : 1142 ) at java . util . concurrent . ThreadPoolExecutor$Worker . run ( ThreadPoolExecutor . java : 617 ) at java . lang . Thread . run ( Thread . java : 745 ) Caused by : org . apache . maven . wagon . authorization . AuthorizationException : Access denied to : https : //repo.protected.example.com/content/groups/internal/org/slf4j/slf4j-log4j12/1.4.3/slf4j-log4j12-1.4.3.pom at org . apache . maven . wagon . providers . http . LightweightHttpWagon . fillInputData ( LightweightHttpWagon . java : 144 ) at org . apache . maven . wagon . StreamWagon . getInputStream ( StreamWagon . java : 116 ) at org . apache . maven . wagon . StreamWagon . getIfNewer ( StreamWagon . java : 88 ) at org . apache . maven . wagon . StreamWagon . get ( StreamWagon . java : 61 ) at org . eclipse . aether . connector . wagon . WagonRepositoryConnector$GetTask . run ( WagonRepositoryConnector . java : 660 ) at org . eclipse . aether . util . concurrency . RunnableErrorForwarder$1 . run ( RunnableErrorForwarder . java : 67 ) at java . util . concurrent . ThreadPoolExecutor . runWorker ( ThreadPoolExecutor . java : 1142 ) at java . util . concurrent . ThreadPoolExecutor$Worker . run ( ThreadPoolExecutor . java : 617 ) at java . lang . Thread . run ( Thread . java : 745 )","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/accessing-basic-auth-protected-maven-repositories","loc":"https://datapile.coffeecrew.org/accessing-basic-auth-protected-maven-repositories"},{"title":"Checklists in LaTeX","text":"Did you ever feel the need for a simple checkbox in a letter? So did I. After searching for a while I did not really come up with a simple copy and pasteable solution to this problem. Most solutions seem to prefer the hyperref package which enables you to put interactive, clickable checkboxes inside your PDF document, but what if you actually need to physically send the document? As it turns out the solution is actually not that hard, a few mbox es and adjustbox es later I had a solution that did the trick for me. At the very basic of the box is this block which actually creates the box and centers the text behind it in the middle of the box. \\mbox { \\adjustbox { stack=cc,fbox }{ \\makebox (6,6) {}} Yes I will. } \\\\ The parameters of the makebox command define how big the box to check will actually be. If you want to add a place where the future checkbox checker can put his signature to sign that he checked one of the checkboxes, you can additionally put something like this into your page, which will render the supplied text and a slightly subscript line. \\mbox { \\begin { minipage } [t] { 18ex } Date and signature \\end { minipage } \\hspace { 1ex } \\rule [-3ex] { 12cm }{ .5pt }} Where the value 18ex of the minipage environment controls the width of the box before the line. The parameters of the rule command are the position of the line ( -3ex ) (which makes it subscript, if you want that superscript make this value positive), the length of the rule ( 12cm ) and the thickness of it ( .5pt ) So if you pimp this a little bit the code for a full letter with checkboxes looks like this .","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/checklists-in-latex","loc":"https://datapile.coffeecrew.org/checklists-in-latex"},{"title":"Reading the Conversation ID From Another Parameter","text":"Note This was tested with Wildfly 10.0.0.Final, Mojarra 2.2.12 and Java JDK 1.8.0_51 When you are working with a @ConversationScoped bean you may want to read JSF 's conversation ID ( cid ) from another request parameter such as for example a parameter named state . At first I tried to find a configuration option to change this behaviour, but failed to find one. In the end the problem can be solved using the org.jboss.weld.context.http.HttpConversationContext class from the Weld CDI implementation if you don't mind being a little implementation dependent. This class allows you to activate a specific context ID or cid so you have access to your normal @ConversationScoped beans. The only pitfall here to remember is that you have to call deactivate() first or you may end up with some kind of a Context is already active Exception. Well you basically do this in your @PostConstruct method. RemapCID.java @PostConstruct private void init () { final HttpServletRequest request = ( HttpServletRequest ) FacesContext . getCurrentInstance (). getExternalContext (). getRequest (); // This basically makes the state parameter the conversation id final String state = request . getParameter ( \"state\" ); httpConversationContext . deactivate (); httpConversationContext . activate ( state ); } I admit this is a pretty pragmatic solution, but it seems to work. Maybe the @ConversationScoped needs to let you specify the parameters to read it's ID from. Hope this helps, until next time.","tags":"Programming","url":"https://datapile.coffeecrew.org/reading-the-conversation-id-from-another-parameter","loc":"https://datapile.coffeecrew.org/reading-the-conversation-id-from-another-parameter"},{"title":"Pro Tools - Playlists","text":"When working with Pro Tools you may find yourself in a position where you need to create a few takes of for example a chorus. Instead of creating a completely new track for every take you do, you can simply create what is called a playlist in Pro Tools. Shortcut You can create a playlist using the right control key and the backslash symbol like RCTRL - \\ . There is also another shortcut assigned if you may not have remapped it in OS X or it may be mapped to something else by default. That shortcut would be LCMD - LALT - LSHIFT - \\ where the letter L denotes the keys on the left side of the keyboard are pressed.","tags":"Music","url":"https://datapile.coffeecrew.org/pro-tools-playlists","loc":"https://datapile.coffeecrew.org/pro-tools-playlists"},{"title":"Creating A Simple Plugin Mechanism In Java","text":"Our goal is to create a simple plugin mechanism in Java. On top of that we want our execution environment to be divided into three distinct phases. These phases are named: PRE_PROCESS PROCESS POST_PROCESS This will allow us to run certain plugins at specific phases during program execution. So if a plugin is for example registered on the PRE_PROCESS hook, we can - and must - guarantee that this plugin will be executed before the PROCESS phase. After we've laid out the basic requirements now, the question is: \"How do we implement that?\". The first thing that probably comes to mind when talking about a plugin mechanism is the standard Java ServiceLoader that was officially opened with the JDK6 and has been in there since the JDK 1.3 days. Another mechanism that can be used to implement a system like this is the Netbeans Lookup API . After defining a basic interface for the plugins we want to create, we'll have a look at both mechanisms to see how they compare. Create Domain Objects Ok, so let's start defining the actual Plugin interface so we have a common hook to execute our plugins on. We make the interface itself very easy and just define a process method in which we'll later have implementations append the actual phase and class name to the String instance that was passed as a parameter. We'll return that String to the caller, so we can subsequently use it and demonstrate very easily when and where the plugin was executed. The interface we want to implement looks like this: package org.coffeecrew.tutorials.simplepluginmechanism ; /** Simple plugin interface. <p/> @author Jens Frey */ public interface Plugin { /** Simple worker method that will append data on the processingToken. <p/> And another. <p/> @param processingToken Token where data should be appended during processing. <p/> @return processingToken that has been worked on. */ public String process ( String processingToken ); } As a next step we define three interfaces that act as marker interfaces so we can differentiate the lifecycle phase the plugin should be run in by the name of the implemented interface. These interfaces are defined as shown below. For the PRE_PROCESS phase: package org.coffeecrew.tutorials.simplepluginmechanism ; /** Marker Interface to tell this is a plugin running in the PRE_PROCESS phase. */ public interface PreProcessable extends Plugin { } For the PROCESS phase: package org.coffeecrew.tutorials.simplepluginmechanism ; /** Marker Interface to tell this is a plugin running in the PROCESS phase. */ public interface Processable extends Plugin { } For the POST_PROCESS phase: package org.coffeecrew.tutorials.simplepluginmechanism ; /** Marker Interface to tell this is a plugin running in the POST_PROCESS phase. */ public interface PostProcessable extends Plugin { } Now that we've defined the interfaces we need some implementations that actually do something. At first we implement a plugin that should be run in the PRE_PROCESS phase. It looks like: package org.coffeecrew.tutorials.simplepluginmechanism ; public class PreProcessPlugin implements PreProcessable { @Override public String process ( String processingToken ) { return processingToken + \"[PRE_PROCESS] \" + this . getClass (). getName () + \"\\n\" ; } } The following implementations are running on the main processing hook PROCESS and look as follows: package org.coffeecrew.tutorials.simplepluginmechanism ; public class ProcessPlugin implements Processable { @Override public String process ( String processingToken ) { return processingToken + \"[PROCESS] \" + this . getClass (). getName () + \"\\n\" ; } } package org.coffeecrew.tutorials.simplepluginmechanism ; public class MoreProcessPlugin implements Processable { @Override public String process ( String processingToken ) { return processingToken + \"[PROCESS] \" + this . getClass (). getName () + \"\\n\" ; } } And finally some implementation for the POST_PROCESS hook: package org.coffeecrew.tutorials.simplepluginmechanism ; public class PostProcessPlugin implements PostProcessable { @Override public String process ( String processingToken ) { return processingToken + \"[POST_PROCESS] \" + this . getClass (). getName () + \"\\n\" ; } } Now that was quite a bit of work, wasn't it? But you'll be shortly rewarded with a nice and pluggable system. Now all we need to be happy is a piece of code that actually runs all of these plugins. Since this code looks slightly different whether we use Java's ServiceLoader mechanism directly or the Netbeans Lookup all the bits 'n pieces required to make this work are outlined in separate sections shown below. Service Loader So let's first have a look at the ServiceLoader mechanism. To prepare implementations of a specific interface for automatic lookup by the ServiceLoader you need to create files in the META-INF/services of your resulting JAR file. I will describe inclusion of that folder on a Maven based project. In order to get the META-INF/services folder into your maven output structure you have to create a folder named resources under src/main . Inside the created resources folder you must place the folder META-INF and underneath that the folder services which Maven will copy when you launch the build. As initially mentioned you need to put files inside the services folder. These files must be named after the interface you want the automatic lookup mechanism to find implementations for. The content of these files is the actual class name of every implementation you want the ServiceLoader to find. If you have multiple implementations of a interface you need to include every implementation class name inside that file delimited by a new line. In our case these three files we need to create must be named (please ensure you choose the correct package name that prepends the interface name): org.coffeecrew.tutorials.simplepluginmechanism.PreProcessable org.coffeecrew.tutorials.simplepluginmechanism.Processable org.coffeecrew.tutorials.simplepluginmechanism.PostProcessable These files must be filled with the following content (please ensure you choose the correct package name that prepends the implementation class name). org.coffeecrew.tutorials.simplepluginmechanism.PreProcessable org.coffeecrew.tutorials.simplepluginmechanism.PreProcessPlugin org.coffeecrew.tutorials.simplepluginmechanism.Processable org.coffeecrew.tutorials.simplepluginmechanism.ProcessPlugin org.coffeecrew.tutorials.simplepluginmechanism.MoreProcessPlugin org.coffeecrew.tutorials.simplepluginmechanism.PostProcessable org.coffeecrew.tutorials.simplepluginmechanism.PostProcessPlugin Now we've hopefully prepared everything the ServiceLoader needs to do it's job. All that's missing now is a simple program that executes our plugin mechanism. Plugin Executor A very simple implementation that will execute all plugins we have written with the ServiceLoader mechanism is quickly written. To guarantee the execution order of the plugins as we initially defined we must implement the code as shown below. package org.coffeecrew.tutorials.simplepluginmechanism ; import java.util.ServiceLoader ; public class SimplePluginExecutorServiceLoader { public static void main ( String [] args ) { String processingToken = \"\" ; final ServiceLoader < PreProcessable > preProcessables = ServiceLoader . load ( PreProcessable . class ); for ( final PreProcessable preProcessable : preProcessables ) { processingToken = preProcessable . process ( processingToken ); } final ServiceLoader < Processable > processables = ServiceLoader . load ( Processable . class ); for ( final Processable processable : processables ) { processingToken = processable . process ( processingToken ); } final ServiceLoader < PostProcessable > postProcessables = ServiceLoader . load ( PostProcessable . class ); for ( final PostProcessable postProcessable : postProcessables ) { processingToken = postProcessable . process ( processingToken ); } System . out . println ( processingToken ); } } As you can see the code is a pretty straight forward implementation. It runs through every implementation that is available for a given interface type and runs the process() method on it. If you did everything right you should now see some output similar to: Sample Output [PRE_PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.PreProcessPlugin [PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.ProcessPlugin [PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.MoreProcessPlugin [POST_PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.PostProcessPlugin As we can see from the output every phase was executed. Where we had two plugins available, both were run as well. This fulfills our basic requirements. Netbeans Lookup By utilizing the Lookup library you can very easily achieve loose coupling, as you can with the ServiceLoader described above. On top of that you get some nice annotations and the ability to give your service implementation a certain priority when it should be run. Now let's have a look at the Netbeans Lookup API and see what's the difference to the ServiceLoader. Well, the obvious first difference is that you need to include a additional library in your project. That library, which was initially strongly coupled to the Netbeans platform itself, was over time separated from the platform so it can be used in applications that are not based on the Netbeans platform and is available as a separate Maven dependency these days. For the dependency resolution to work you need to include the Netbeans repository in your pom.xml so you're able to get a hold of the library as this library is not available in one of the well know central repositories as for example The Central Repository . There is a discussion going on about this which may or may not lead to a centrally available dependency in the future. You can however reference the library by appending the following information into your projects pom.xml file. Netbeans Lookup Maven Dependencies <repositories> <repository> <id> Netbeans Repository </id> <url> http://bits.netbeans.org/maven2/ </url> </repository> </repositories> <dependencies> <dependency> <groupId> org.netbeans.api </groupId> <artifactId> org-openide-util-lookup </artifactId> <version> RELEASE73 </version> </dependency> </dependencies> Don't forget to execute a build of your project, so maven can download the newly added dependency for you. If you're still working on the initial project where we've used the ServiceLoader mechanism please make sure you delete the resources folder now, you don't need it in conjunction with the Lookup API . For the Lookup API to work you need to add annotations to your domain objects. These annotations will create the files with the interface name and fill their content with the class names that provide an implementation for that interface. This probably sounds more difficult than it actually is now, but it's actually a trivial thing to do. You simply need to add a little @ServiceProvider annotation in front of your class name. To make this as simple as possible I print the four classes again, their content is the same as outlined in the Create Domain Objects section, just with the added annotation. PreProcessPlugin.java package org.coffeecrew.tutorials.simplepluginmechanism ; import org.openide.util.lookup.ServiceProvider ; @ServiceProvider ( service = PreProcessable . class ) public class PreProcessPlugin implements PreProcessable { @Override public String process ( String processingToken ) { return processingToken + \"[PRE_PROCESS] \" + this . getClass (). getName () + \"\\n\" ; } } ProcessPlugin.java package org.coffeecrew.tutorials.simplepluginmechanism ; import org.openide.util.lookup.ServiceProvider ; @ServiceProvider ( service = Processable . class , position = 10 ) public class ProcessPlugin implements Processable { @Override public String process ( String processingToken ) { return processingToken + \"[PROCESS] \" + this . getClass (). getName () + \"\\n\" ; } } MoreProcessPlugin.java package org.coffeecrew.tutorials.simplepluginmechanism ; import org.openide.util.lookup.ServiceProvider ; @ServiceProvider ( service = Processable . class ) public class MoreProcessPlugin implements Processable { @Override public String process ( String processingToken ) { return processingToken + \"[PROCESS] \" + this . getClass (). getName () + \"\\n\" ; } } PostProcessPlugin.java package org.coffeecrew.tutorials.simplepluginmechanism ; import org.openide.util.lookup.ServiceProvider ; @ServiceProvider ( service = PostProcessable . class ) public class PostProcessPlugin implements PostProcessable { @Override public String process ( String processingToken ) { return processingToken + \"[POST_PROCESS] \" + this . getClass (). getName () + \"\\n\" ; } } Now that we've changed our domain object to utilize the annotations provided by the Lookup API we need an executor method to run our plugins in. All that changes compared to the ServiceLoader approach is the way you look up the implementations. It's just a different API call. Plugin Executor Again we'll show a very simple implementation that will execute all plugins we have written. SimplePluginExecutorLookupAPI.java package org.coffeecrew.tutorials.simplepluginmechanism ; import java.util.Collection ; import org.openide.util.Lookup ; public class SimplePluginExecutorLookupAPI { public static void main ( String [] args ) { String processingToken = \"\" ; final Collection <? extends PreProcessable > preProcessables = Lookup . getDefault (). lookupAll ( PreProcessable . class ); for ( final PreProcessable preProcessable : preProcessables ) { processingToken = preProcessable . process ( processingToken ); } final Collection <? extends Processable > processables = Lookup . getDefault (). lookupAll ( Processable . class ); for ( final Processable processable : processables ) { processingToken = processable . process ( processingToken ); } final Collection <? extends PostProcessable > postProcessables = Lookup . getDefault (). lookupAll ( PostProcessable . class ); for ( final PostProcessable postProcessable : postProcessables ) { processingToken = postProcessable . process ( processingToken ); } System . out . println ( processingToken ); } } As you can see this code is basically the same as with the ServiceLoader approach. It runs through every implementation that is available for a given interface type and runs the process() method on it. However, you might notice that the output slightly changed. With the Lookup API the MoreProcessPlugin is executed before the ProcessPlugin . This is something we may not want in case we care about the order in which these plugins need to run when they are executed within the same phase. Service Loader Output [PRE_PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.PreProcessPlugin [PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.ProcessPlugin [PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.MoreProcessPlugin [POST_PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.PostProcessPlugin Lookup API Output [PRE_PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.PreProcessPlugin [PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.MoreProcessPlugin [PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.ProcessPlugin [POST_PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.PostProcessPlugin Luckily there s a mechanism which allows you to control exactly that behavior. And it's built in right into the Lookup API . The @ServiceProvider annotation let's you set a position attribute. This position attribute defines when this implementation should be run, if another implementation is also available. The higher the position number is, the earlier the implementation is run. Since the default position value is 0 it is sufficient to assign a value only to the ProcessPlugin implementation. Changing the @ServiceProvider line in the ProcessPlugin to @ServiceProvider ( service = Processable . class , position = 10 ) Will result in the following output which reflects the actual processing order of the ServiceLoader example. Comparison As you could see the Lookup API simplifies work by generating the files you'd normally have to create in META-INF/services manually. By the generative approach and the position attribute you can also guarantee a specific execution order without the hassle to manually reorder the content of the files in META-INF/services . The Lookup API offers much more advanced features aside from the ones that were mentioned here, like for example Lookup templates that allow you to query information on an object without instantiating it or listening to changes in a Lookup. You could also lookup different implementations for a service based on it's MIME type. One More Thing Now I have actually one more thing I want to share with you. This approach works for both previously introduced plugin mechanisms, but will be included in the Lookup API example only. It allows you to add or remove processing phases without having to rewrite all your processing code. This can simply be achieved by assigning the interface classes to an enumeration type. So let's first implement the enumeration type that ties together the processing phase and the interface assigned to it. Phase.java package org.coffeecrew.tutorials.simplepluginmechanism ; public enum Phase { // PRE_PROCESS(PreProcessable.class), PROCESS ( Processable . class ), POST_PROCESS ( PostProcessable . class ); private final Class <? extends Plugin > plugin ; private Phase ( Class <? extends Plugin > plugin ) { this . plugin = plugin ; } public Class <? extends Plugin > getPhaseInterface () { return plugin ; } } As you can see the implementation is fairly trivial, yet effective. Now all we need is an adapted executor for this to work. An implementation that utilizes the new idea looks as follows: SimplePhaseExecutor.java package org.coffeecrew.tutorials.simplepluginmechanism ; import java.util.Collection ; import org.openide.util.Lookup ; public class SimplePhaseExecutor { public static void main ( String [] args ) { String processingToken = \"\" ; for ( final Phase p : Phase . values ()) { final Collection <? extends Plugin > processables = Lookup . getDefault (). lookupAll ( p . getPhaseInterface ()); for ( final Plugin plugin : processables ) { processingToken = plugin . process ( processingToken ); } } System . out . println ( processingToken ); } } Execution of the above code will result in the following output: Lookup API Output [PRE_PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.PreProcessPlugin [PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.ProcessPlugin [PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.MoreProcessPlugin [POST_PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.PostProcessPlugin Which is what we have expected it to do. The cool part however is - if you need to change the execution order of the phases, add a new phase, or delete a phase - you do not need to change the executor code but only the order or number of elements in the Phase enumeration. So should you decide to no longer include the PRE_PROCESS phase anymore you just need to remove the phase from the enumeration type, re-run the example aaaand: Output - PRE_PROCESS Phase Removed [PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.ProcessPlugin [PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.MoreProcessPlugin [POST_PROCESS] org.coffeecrew.tutorials.simplepluginmechanism.PostProcessPlugin There you go, no more annoying PRE_PROCESSING , just as expected :) If you like you can clone the two projects from Github: ServiceLoader Version LookupAPI Version Hope you enjoyed the post! Leave comments, like 'n share!","tags":"Programming","url":"https://datapile.coffeecrew.org/creating-a-simple-plugin-mechanism-in-java","loc":"https://datapile.coffeecrew.org/creating-a-simple-plugin-mechanism-in-java"},{"title":"Grenade - Cover Version","text":"For the first time ever I am on YouTube! So feel free to check out the cover version of Bruno Mars' song \"Grenade\". Hope you enjoy it!","tags":"Music","url":"https://datapile.coffeecrew.org/grenade-cover-version","loc":"https://datapile.coffeecrew.org/grenade-cover-version"},{"title":"Unser Lied","text":"Deutsch Dieses Lied hab ich für die Hochzeit zwischen Ilka und Alexander geschrieben. Ich hoffe beide werden eine lange Zeit Freude an diesem Lied haben. English I wrote this song for the wedding between Ilka and Alexander. I very much hope they both enjoy the title for a long time. The Song John C. Flow · Unser Lied Can be found at: https://soundcloud.com/john-c-flow/unser-lied The Lyrics Words & Music: Jens Frey Tempo: 83 BPM Key: D Verse [D]Komm her, Halt mich [A]fest, Nimm [Hm]mich in Deine Arme, [G]Hier und [Gm]jetzt. Ich [A]will Dich [D]fühln, ganz nah bei [A]mir, Will [Hm]deinen Atem spürn, Der mich [G]wärmt, so dass ich nicht [Gm]frier. Ich will Dich [D]halten, für [A]immer in meinem Arm, könnt auf [Hm]ewig mit Dir tanzen, doch die Mu[G]sik ist nicht mehr [Gm]an. Bridge [Em]Ich schalt das [D]Radio ein, Ich [Em]dreh voll [D]auf, [Em]Spürst du den [D]Beat? Komm [A]Tanz mit mir, denn Chorus Das unser [D]Lied, in dem die [A]Zeit nie entflieht, Hier ist [F#m]der Moment gefangen, In [G]dem wir uns ver-[Gm]liebt, Das ist unser [D]Lied, In dem uns [A]nichts passieren kann, Hier sind wir [Hm]beide unverwundbar, Hier ist [G]sichrer Hafen, [A]Sichres Ge[D]biet. Verse [D]Ich will immerzu, in [A]Deiner Nähe sein, bin immer [Hm]mit Dir in Gedanken, e[G]gal wo ich [Gm]bin, Kann [A]einfach [D]nicht, ohne Deine [A]Liebe sein, Brauch sie [Hm]wie die Luft zum atmen, [G]lass mich nie al-[Gm]lein. Bridge [Em]Ich schalt das [D]Radio ein, Ich [Em]dreh voll [D]auf, [Em]Spürst du den [D]Beat? Komm [A]Tanz mit mir, denn Chorus Das ist unser [D]Lied, in dem die [A]Zeit nie entflieht, Hier ist [F#m]der Moment gefangen, In [G]dem wir uns ver-[Gm]liebt, Das ist unser [D]Lied, In dem uns [A]nichts passieren kann, Hier sind wir [Hm]beide unverwundbar, Hier ist [A]sichrer Hafen, [A]Sichres Ge[D]biet. Solo [D/A/Hm/G/A D/A/Hm/A/A/D ] Chorus Das ist unser [D]Lied, in dem die [A]Zeit nie entflieht, Hier ist [F#m]der Moment gefangen, In [G]dem wir uns ver-[Gm]liebt, Das ist unser [D]Lied, In dem uns [A]nichts passieren kann, Hier sind wir [Hm]beide unverwundbar, Hier ist [G]sichrer Hafen, [A]Sichres Ge[D]biet. [G]Lass es uns nie ver-[A]gessen, unser [D]Lied [G]Lass es uns nie ver-[A]gessen, unser [D]Lied","tags":"Music","url":"https://datapile.coffeecrew.org/unser-lied","loc":"https://datapile.coffeecrew.org/unser-lied"},{"title":"Goondown","text":"Just playing around with the software, seems to be a mix between Trance and Easy Listening … John C. Flow · Goondown Can be found at: https://soundcloud.com/john-c-flow/goondown","tags":"Music","url":"https://datapile.coffeecrew.org/goondown","loc":"https://datapile.coffeecrew.org/goondown"},{"title":"Goodbye","text":"The song John C. Flow · Goodbye Can be found at: https://soundcloud.com/john-c-flow/goodbye The lyrics Verse [F#m]Like a lonesome voice, [A]in the crowd, [F#m]like a broken toy, [A]left on the ground, [Bm]I feel like I've been left behind, [D]been canceled out, [Bm]no one's right here by my side, [Esus4]no one is a[E]round. [F#m]I've been on this empty road, [A]for quite some time, [F#m]I've been searching out for love, [A]but never could find mine. [Bm]It always ran away from me, [D]I never was that fast, [Bm]I had just a simple dream, [D]but it couldn't l[Esus4]a—-a[E]st … Chorus [A]Good-[C#m7]bye, [D]my [E]everlasting dre[A]am, [A] [C#m7] [D] [E] [A] [A]Good-[C#m7]bye, [D]love is [E]never like it s[A]eems [A] [C#m7] [D] [E] Cause when there's [Dmaj7]love there's misery, which is a[Asus2/C#]lways finding me, love has a b[Bm]etter place to [Esus4]be, like [F#5]me. Verse [F#m]If only I could understand, [A]why it is me, [F#m]is it just my bad luck or my [A]destiny? [Bm]what is it what the others do? what [D]is it? Please tell me. [Bm]I guess I will never know, so I say [D]goodbye to my [Esus4]drea—[E]m. Chorus [A]Good-[C#m7]bye, [D]my [E]everlasting dre[A]am, [A] [C#m7] [D] [E] [A] [A]Good-[C#m7]bye, [D]love is [E]never like it s[A]eems [A] [C#m7] [D] [E] The only [D]thing I [E]now do [F#m]fear, is [D]someone [E]getting [F#m]near, Who will [D]brake my [E]heart and [F#m]then, I have to [Esus4]say goodbye ag[E]ain. Solo over [A][C#m7][D][E] [A][C#m7][D][E] [A][C#m7][D][E] [Dmaj7][C#m7][Esus4][E] Chorus [A]Good-[C#m7]bye, [D]my [E]everlasting dre[A]am, [A] [C#m7] [D] [E] [A] [A]Good-[C#m7]bye, [D]love is [E]never like it s[A]eems [A] [C#m7] [D] [E] Cause when there's [Dmaj7]love there's misery, which is a[Asus2/C#]lways finding me, love has a b[Bm]etter place to [Esus4]be, like [F#5]me.","tags":"Music","url":"https://datapile.coffeecrew.org/goodbye","loc":"https://datapile.coffeecrew.org/goodbye"},{"title":"Use your own website as OpenID login","text":"If you want to use OpenID as an authentication mechanism, but are afraid of the fact that your OpenID provider may die in the future, or you simply might want to use another provider in the future, you can use a delegation model with OpenID. A reason to change the OpenID provider might be, that your current OpenID provider does not support an authentication mechanism you like to, as for example the YubiKey or something like that. Let's say you want to use http://xyz.example.com as your OpenID and you want to use http://clavid.com as your Identity Provider, you have to execute the following steps. Create a (sub-)domain for example.com called xyz. This can for example be done by adding another virtual host to your apache configuration. The configuration might look like the following one: <VirtualHost xx.xx.xx.xx:80 > ServerAdmin webmaster@example.com ServerName xyz.example.com DocumentRoot /var/www/xyz/ <Directory /var/www/xyz/ > # Options Indexes MultiViews AllowOverride None Order allow,deny allow from all </Directory> ErrorLog /var/log/apache2/error_xyz.log # Possible values include: debug, info, notice, warn, error, crit, # alert, emerg. LogLevel warn CustomLog /var/log/apache2/access_xyz.log combined </VirtualHost> Create a index.html file inside your document root As a next step you have to create a index.html file in your document root (in this case /var/www/xyz ) with the following content in order for OpenID services being able to find your current identity provider: < html > < head > < title > Jens' OpenID delegation page </ title > < link rel = \"openid.server\" href = \"http://www.clavid.com/provider/openid\" /> < link rel = \"openid2.provider\" href = \"http://www.clavid.com/provider/openid\" /> < link rel = \"openid.delegate\" href = \"http://jens.clavid.com\" /> < link rel = \"openid2.local_id\" href = \"http://jens.clavid.com\" /> </ head > < body > < h1 > This page is used for OpenID delegation. </ h1 > For more information on OpenID either visit < a href = \"http://openid.net\" > http://openid.net < a > or < a href = \"http://clavid.com\" > http://clavid.com </ a > </ body > </ html > Ready From now on you can use http://xyz.example.com as your OpenID, which will, as currently configured, be redirecting to http://clavid.com where authentication will take place. References You can read all about OpenID in the specification, but the part used for this example is available at: http://openid.net/specs/openid-authentication-1_1.html#delegating_authentication","tags":"Security","url":"https://datapile.coffeecrew.org/use-your-own-website-as-openid-login","loc":"https://datapile.coffeecrew.org/use-your-own-website-as-openid-login"},{"title":"Customizing Emacs","text":"Note This tutorial was tested with GNU Emacs 23.0.91.1 Some of you might be forced to spent nearly the whole day in a text editor like e.g. emacs to do their work. This usually is especially true for developers, that have to write code the whole day and therefore are forced to look into their editor the whole day. So why not customize it a little, so work might be more pleasant in the end? This article will show you how you can customize emacs to hopefully suit your needs. Since I am using Ubuntu, which is a Debian based distribution, the installation of packages might vary for your distribution. Prerequisites In order for this customization to work, you need to get some things first. This includes the development version of emacs, which in my distribution is marked as emacs-snapshot, and the Terminus font, which is according to many users the font if you have to work long on your computer. That's what I can say too, the font is very pleasant on the eyes. So, be sure to have the following stuff available: The Terminus font Emacs For the development (snapshot) version of emacs you'd probably have to check out the CVS repository, if you're lucky, version 23 is released when you read this ;). On an Ubuntu based installation, these packages are quite easy to get, simply enter the following commands in your terminal. j@sigusr1:$ sudo aptitude install \\ console-terminus xfonts-terminus \\ xfonts-terminus-dos xfonts-terminus-oblique \\ emacs-snapshot emacs-snapshot-gtk If you do have the non-snapshot edition of emacs already installed on your system, you might want to update your default, be executing the following commands and select the snapshot as the default being started when you type emacs : $ sudo update-alternatives --config emacs $ sudo update-alternatives --config emacsclient You should now be able to type emacs into your terminal and the emacs-snapshot will be started. Color Themes I like colors, and I think the basic color theme that comes with emacs is not very nice. So I decided to install some color themes. Luckily these color themes can be easily installed on Ubuntu. If you are using another distribution which might not have support for that, you might want to try downloading and installing it manually . For the automatic version, simply do: $ sudo apt-get install emacs-goodies-el After the installation completes, you should be able to start emacs and select a color theme like \"Subtle Hacker\" or \"Gnome 2\" with M-x color-theme-select . The \"Save customization\" feature in the snapshot I am using ( GNU Emacs 23.0.91.1) does not seem to work unfortunately. There is one \"trick\" though that might work; if the customization file does not yet exist, saving seems to work. Customization Files If you externalize your configuration into a -custom.el file, you end up with two files, the .emacs and the .emacs-custom.el file (or whatever you name it). My files look as follows. References http://www.gnu.org/software/emacs/emacs-faq.html#Installing-Emacs http://www.is-vn.bg/hamster http://www.nongnu.org/color-theme http://homepages.inf.ed.ac.uk/s0243221/emacs http://amrmostafa.org/bearable-emacs-recipe http://peadrop.com/blog/2007/01/06/pretty-emacs http://fractal.csie.org/~eric/wiki/Terminus_font http://copyleft.free.fr/wordpress/index.php/2009/04/24/nice-fonts-with-emacs-23-snapshot","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/customizing-emacs","loc":"https://datapile.coffeecrew.org/customizing-emacs"},{"title":"Roller template","text":"Since there has been some interest in the roller template that I have designed, I decided to upload it here, so you can freely use it. You probably want to exchange the pictures and if you do have to modify any of them template files, I suggest taking a deeper look into the template guide . Download template","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/roller-template","loc":"https://datapile.coffeecrew.org/roller-template"},{"title":"XviD, AVI , FLV , MKV support for FrontRow on Mac OS X","text":"Have you ever wondered why FrontRow does not play your precious AVI /XviD/ MKV and the like files? The Answer is the codecs are missing. The missing codecs need to be installed as extensions to Quicktime since FrontRow uses Quicktime to play it's content listed in the library. The logical next step is to download the missing libraries and install them one by … really? Actually - no. Luckily there are a few guys that have built a simple solution to install these missing codecs on your mac. Download the codec pack from perian.org and have fun watching your AVI /XviD/ MKV encoded videos.","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/xvid-avi-flv-mkv-support-for-frontrow-on-mac-os-x","loc":"https://datapile.coffeecrew.org/xvid-avi-flv-mkv-support-for-frontrow-on-mac-os-x"},{"title":"Using Java Enumerations","text":"This article shows a basic implementation of a Java enumeration type that you can use to do a switch on Strings for example. Introduction Now for the moment let's assume that we want to write a program that is able tell us if a programming language is more hardware adjacent than another. Since we already know the adjacency of the programming language, we can group that into the enumeration. So, we're basically enriching the Enumeration constant with some additional information that we later can easily gather from the object. To distinguish the various adjacency levels we are needed to supply some additional information to the enum so we can later ask it if a programming language is more hardware adjacent than another. In addition to that, we want to refer to the programming language with it's long, real name. So instead of just having print ASM we want to be able to extract that information as Assembler from the enum type. The c0de We'll now have a look at the code and how it's actually implemented. As you can see, you cannot rely on the default implementation of the toString() method when you do want to print the enums name. Exactly for this the name() method was introduced. For internal handling of the data structure Java holds an ordinal value too, so the enums can be located correctly. package org.coffeecrew.examples.enumeration ; public enum ProgrammingLanguage { /* ASM is hardware ;) */ ASM ( \"Assembler\" , - 10 ), C ( \"C\" , 0 ), CPP ( \"C ++\" , 10 ), Java ( \"Java\" , 20 ); public enum Adjacence { UNSET , LESS , EQUAL , MORE }; private ProgrammingLanguage ( String longName , int hardwareAdjacence ) { this . longName = longName ; this . hardwareAdjacence = hardwareAdjacence ; } private final String longName ; private final int hardwareAdjacence ; public int hardwareAdjacence () { return hardwareAdjacence ; } public String longName () { return this . longName ; } public Adjacence isMoreAdjecent ( ProgrammingLanguage than ) { Adjacence toReturn = Adjacence . UNSET ; if ( this . hardwareAdjacence () < than . hardwareAdjacence ()) { toReturn = Adjacence . LESS ; } else if ( this . hardwareAdjacence () == than . hardwareAdjacence ()) { toReturn = Adjacence . EQUAL ; } else if ( this . hardwareAdjacence () > than . hardwareAdjacence ()) { toReturn = Adjacence . MORE ; } return toReturn ; } @Override public String toString () { StringBuilder sb = new StringBuilder ( \"Name: \" ); sb . append ( name ()) . append ( \"\\nLong name: \" ) . append ( longName ) . append ( \"\\nOrdinal: \" ) . append ( ordinal ()) . append ( \"\\nHardware adjacency: \" ) . append ( hardwareAdjacence ) . append ( \"\\n\\n\" ); return sb . toString (); } } Next we probably want to have a sample program calling this wonderful enum … so why not develop one? package org.coffeecrew.examples.enumeration ; public class Main { public static void main ( String [] args ) { for ( ProgrammingLanguage pl : ProgrammingLanguage . values ()) { printProgrammingLanguage ( pl ); printMoreAdjacent ( ProgrammingLanguage . C , pl ); } } public static void printProgrammingLanguage ( ProgrammingLanguage pl ) { System . out . println ( pl ); } public static void printMoreAdjacent ( ProgrammingLanguage moreAdjacent , ProgrammingLanguage than ) { ProgrammingLanguage . Adjacence adj = moreAdjacent . isMoreAdjecent ( than ); StringBuilder text = new StringBuilder (); text . append ( moreAdjacent . name ()) . append ( \" (\" ) . append ( moreAdjacent . longName ()) . append ( \")\" ) . append ( \" is \" ); switch ( adj ) { case LESS : text . append ( adj . name ()); break ; case EQUAL : text . append ( adj . name ()); break ; case MORE : text . append ( adj . name ()); break ; default : text . append ( adj . name ()); } text . append ( \" hardware adjacent than \" ) . append ( than . name ()) . append ( \" (\" ) . append ( than . longName ()) . append ( \")\" ); System . out . println ( text . toString ()); } } Btw. with this concept you can also do the somehow often wanted switch on strings concept (just switch on the enum and get the String name).","tags":"Programming","url":"https://datapile.coffeecrew.org/using-java-enumerations","loc":"https://datapile.coffeecrew.org/using-java-enumerations"},{"title":"Programming with the APR - Using APR HashTables","text":"This short article will show how to use the Apache Portable Runtime ( APR ) with it's built in hashtable. Introduction If you are in need to place data in a memory structure to access it quickly, you are probably best with a hash table data type. The Apache Portable Runtime ( APR ) luckily, along some others like e.g. apr_table_t or apr_array_header_t (both defined in apr_tables.h ), provides such a data type to you. Hashtables do have the big advantage that you can supply them any data type you like. The next big thing with hashtables is that they are usually very efficient if the number of elements that they are holding grows. You can download the file here . Let's hash In order to demonstrate hashtables we are using a very simple data structure which holds a date, a username and a password. We then set some values onto this data structure and save the created structure into the hashtable. After storing that object into the hashtable we are reading the objects back from the hashtable and output it's contents. The c0de Now that you do have some overview of what we are actually doing here, it's time to show you some code. I think it pretty much speaks for itself. You should however, if you are using strings as keys, use the special APR_HASH_KEY_STRING value to indicate a string valued key to APR . This will use strlen(key) to compute the length ( NUL terminator is not included there). #include <apr.h> #include <apr_hash.h> #include <apr_time.h> #define APR_WANT_STDIO #include <apr_want.h> struct userRecord { apr_time_t creationDate ; char username [ 30 ]; char password [ 30 ]; }; void print ( struct userRecord * user ) { apr_pool_t * p = NULL ; char * timeReadable = NULL ; apr_pool_create ( & p , NULL ); int i = 0 ; timeReadable = apr_palloc ( p , APR_RFC822_DATE_LEN ); apr_rfc822_date ( timeReadable , user -> creationDate ); printf ( \"Username: \\t\\t %s \\n \" , user -> username ); printf ( \"Password: \\t\\t %s \\n \" , user -> password ); printf ( \"CreationDate: \\t\\t %s \\n \" , timeReadable ); apr_pool_destroy ( p ); return ; } /* Compile with * $> export APR_LIBS=\"`apr-1-config --cflags --cppflags --includes --ldflags --link-ld --libs`\" * $> export APU_LIBS=\"`apu-1-config --includes --ldflags --link-ld --libs`\" * $> gcc $APR_LIBS $APU_LIBS aprHashtable.c -o aprHashtable */ int main ( int argc , const char * const * argv ) { apr_status_t rv ; apr_pool_t * p = NULL ; struct userRecord * cUser = NULL ; struct userRecord * readUser = NULL ; int i = 0 ; char countName [ 12 ]; apr_hash_index_t * hidx = NULL ; apr_app_initialize ( & argc , & argv , NULL ); atexit ( apr_terminate ); apr_pool_create ( & p , NULL ); apr_hash_t * ht = apr_hash_make ( p ); apr_cpystrn ( countName , \"Jens Frey \" , 12 ); for ( i = 0 ; i < 26 ; i ++ ) { countName [ 10 ] = ( char ) i + 65 ; cUser = apr_palloc ( p , sizeof ( struct userRecord )); apr_cpystrn ( cUser -> username , countName , strlen ( countName ) + 1 ); apr_cpystrn ( cUser -> password , \"secret\" , strlen ( \"secret\" ) + 1 ); cUser -> creationDate = apr_time_now (); apr_hash_set ( ht , cUser -> username , APR_HASH_KEY_STRING , cUser ); print ( cUser ); } for ( hidx = apr_hash_first ( p , ht ); hidx ; hidx = apr_hash_next ( hidx )) { apr_hash_this ( hidx , NULL , NULL , ( void * ) & readUser ); print ( readUser ); } readUser = apr_hash_get ( ht , \"Jens Frey G\" , APR_HASH_KEY_STRING ); printf ( \" \\n\\n \" ); print ( readUser ); printf ( \"Hashtable size: %d bytes \\n \" , apr_hash_count ( ht ) * sizeof ( struct userRecord ) + apr_hash_count ( ht ) * sizeof ( readUser -> username )); apr_terminate (); return rv ; }","tags":"Programming","url":"https://datapile.coffeecrew.org/programming-with-the-apr-using-apr-hashtables","loc":"https://datapile.coffeecrew.org/programming-with-the-apr-using-apr-hashtables"},{"title":"Programming with the APR - Using MD5","text":"This article intends to show how to basically use the MD5 hashing algorithm that ships with the Apache Portable Runtime ( APR ) library. Introduction Sometimes you are really in need for some MD5 hashed strings. Most of the time you are in such a need if you want to create a custom password store where you don't want an attacker to easily get the password if he compromises your system. So MD5 hashed password are great for such a purpose. Luckily the Apache Portable Runtime ( APR ) provides such a MD5 hashing mechanism to you, so you can easily use that and do not have to struggle with the complex details of how to actually create a MD5 hash. Hashing Hashing basically describes a way of taking an arbitrary length input and calculating that down into a secure, tamperproof cryptographic value that can only be recalculated if the same input was given again. The basic idea is that the calculation that is necessary to produce the hashed output is very easy to perform, but if you just have the hashed version of the password you cannot easily reverse that operation (the reverse operation is very complex). Salting If you are creating a password store on your own, you probably don't want a simple MD5 hashing mechanism, which the APR provides to you. You probably want to add some salt to your password management mechanism, since salting the password makes brute force attacks with rainbow tables onto the hashed password repository so much more inconvenient for the attacker. Salting, for those who don't know, simply sort of \"enriches\" your password with some random bytes, that will be thrown into the mix when hashing the actual password. Since a hash algorithm is only a good one if it flips about 50 percent of the bits in the output if you change a single input bit, you can imagine that a few added bits should absolutely be sufficient to change the result of the hash operation. In order for the algorithm to be able to reconstruct the same hash again, he of course needs to know the salt that was initially used to create the corresponding hash. Therefore this salt value will be written in front of the final hashed password string. A typical MD5 hash, or sometimes called an MD5 digest will look like: $apr1$XGOEPMa5$eUAF1NzTmHoqGZJSD5P4q1 The c0de The code itself is pretty straight forward. You might notice that I'm not using any APR data pool within the program itself. This is simply due to the fact that I'm not needing any ;). The program first initializes internal APR data structures and registers a termination function. Then a randomized salt value is generated (you could also use a fixed salt, but that is not recommended). Finally the MD5 encoding is performed. The most problematic part here is to figure out what the actual length of the result will be. From what I observed the result is no longer than 37 characters, but that might change if the APR people e.g. decide to change their $apr1$ prefix which indicates the custom salting algorithm to the library. #include <apr.h> #include <apr_base64.h> #include <apr_general.h> #include <apr_md5.h> #define APR_WANT_STDIO #include <apr_want.h> /* This is neccessary since there seems to be * no real information to gather how long the actual * result string will be when the encoder finishes it's * work. * * Using another contellation, this should not be a problem, * since we would of course allocate the final result memory * from an APR pool. Where memory is managed, and the final length * of the result is known. * * During several trial and error phases i observed the result string * to be no longer than 37 characters. But that might change if the * e.g. change the apr id, where the \"custom algorithm\" is detected. */ #define MAX_STRING_LEN 256 #define SALT_LEN 9 void randomizeSalt ( char * resultSalt ) { apr_status_t rv ; char salt [ SALT_LEN ]; char b64Salt [ apr_base64_encode_len ( SALT_LEN )]; apr_base64_encode ( b64Salt , salt , SALT_LEN ); printf ( \"Salt array before randomization: \\t %s \\n \" , b64Salt ); rv = apr_generate_random_bytes ( salt , SALT_LEN - 1 ); salt [ SALT_LEN -1 ] = '\\0' ; apr_base64_encode ( b64Salt , salt , SALT_LEN ); printf ( \"Salt array after randomization: \\t %s \\n \" , b64Salt ); /* As we do just need 8 random characters, we just * copy them (remember the 9th char is set to '\\0' earlier */ apr_cpystrn ( resultSalt , b64Salt , SALT_LEN ); return ; } /* Compile with * $> export APR_LIBS=\"`apr-1-config --cflags --cppflags --includes --ldflags --link-ld --libs`\" * $> export APU_LIBS=\"`apu-1-config --includes --ldflags --link-ld --libs`\" * $> gcc $APR_LIBS $APU_LIBS aprMd5.c -o aprMd5 */ int main ( int argc , const char * const * argv ) { unsigned char md5Digest [ APR_MD5_DIGESTSIZE ]; const char passwordToHash [] = \"This is my very secure extrme 1337 pa55w0r)\" ; /* This gives us the salt, so the same password * will not produce the same hash, given the assumption, * that the salt of course changes. * Using this static string is, of course not any safer * then just using the standard MD5 hashing. * * This MD5 version uses an APR specific salting. */ //char salt[] = \"12345678\"; char salt [ 9 ]; apr_status_t rv ; /* Actually use the app_initialize funciton if you are * not writing a library. * * This function is defined in apr_general.h */ apr_app_initialize ( & argc , & argv , NULL ); atexit ( apr_terminate ); randomizeSalt ( salt ); unsigned char md5DigestSalted [ MAX_STRING_LEN ]; /* This actually hashes the password into a final * already in ASCII printable characters encoded * string */ apr_md5_encode ( passwordToHash , salt , md5DigestSalted , sizeof ( md5DigestSalted )); printf ( \"The MD5 digest salted of: \\n %s \\n looks like: \\n %s \\n \" \"and is %d characters long \\n \" , passwordToHash , md5DigestSalted , strlen ( md5DigestSalted )); /* Now see if we can validate our \"normal\" password against the * hashed version. */ rv = apr_password_validate ( passwordToHash , md5DigestSalted ); printf ( \"Testing password: %s \\n \" , passwordToHash ); if ( rv == APR_SUCCESS ) { printf ( \"[SUCCESS] The supplied password validated correctly against the hash \\n \" ); } else { printf ( \"[FAILURE] The supplied password did not validate \\n \" ); } /* Offset the original password by one character, so this should not * be valid anymore. */ rv = apr_password_validate ( & passwordToHash [ 1 ], md5DigestSalted ); printf ( \"Testing password: %s \\n \" , & passwordToHash [ 1 ]); if ( rv == APR_SUCCESS ) { printf ( \"[SUCCESS] The supplied password validated correctly against the hash \\n \" ); } else { printf ( \"[FAILURE] The supplied password did not validate \\n \" ); } apr_terminate (); return 0 ; }","tags":"Programming","url":"https://datapile.coffeecrew.org/programming-with-the-apr-using-md5","loc":"https://datapile.coffeecrew.org/programming-with-the-apr-using-md5"},{"title":"Programming with the APR - Using apr_getopt","text":"This article will show you how to use the built in command line parser that comes with the APR . There will be two source files, one showing you how to use apr_getopt just to parse simple, single options and the other peace of source will show you how to use it with so called long options. You can download the single option parser here and the long options parser here . Note The program supplied should actually use apr_app_initialize(&argc, &argv, NULL); since apr_initialize() is intended for library use only. Prerequisites As always, you need to have APR libraries installed in order to be able to use them. You'll additionally need the header files too, so if you're installing from some distribution specific mechanism, be sure to have the \"-dev\" packages installed as well. Explanation There is really not that much to explain this time. We first initialize APR , create a pool, then initialize the getopt parser and then we're walking through the options specified on the command line. The most notable part here is the line: cmdLineArgs->interleave= 1; . Setting the interleave to one allows us to have options and final arguments specified \"wildly\" on the command line. That means that the order of arguments is not relevant. You can either supply the options like ./aprGetoptLong --choose what -h lalalal or you can type: ./aprGetoptLong --choose what lalala -h which, in this case would lead to the same result. Simple options code #include <apr.h> #include <apr_file_io.h> #include <apr_getopt.h> /* Compile with * $> export APR_LIBS=\"`apr-1-config --cflags --cppflags --includes --ldflags --link-ld --libs`\" * $> export APU_LIBS=\"`apu-1-config --includes --ldflags --link-ld --libs`\" * $> gcc $APR_LIBS $APU_LIBS aprGetopt.c -o aprGetopt */ int main ( int argc , const char * const * argv ) { apr_pool_t * p = NULL ; apr_getopt_t * cmdLineArgs = NULL ; apr_status_t rv ; char optChar ; const char * optArg = NULL ; /* Will hold the position for the non optional * args in the APR parsed argv */ int processedOptions = 0 ; /* cleanly handle fileIO this time */ apr_file_t * out = NULL ; apr_file_t * err = NULL ; /* init APR, create memory pool */ apr_initialize (); atexit ( apr_terminate ); apr_pool_create ( & p , NULL ); /* Open stdin, stderr */ apr_file_open_stdout ( & out , p ); apr_file_open_stderr ( & err , p ); /* init APRs getopt */ apr_getopt_init ( & cmdLineArgs , p , argc , argv ); /* If not using the getopt_long version, this * this is ignored */ //cmdLineArgs->interleave = 1; /* Now step through the options given */ while (( rv = apr_getopt ( cmdLineArgs , \"hc:\" , & optChar , & optArg )) == APR_SUCCESS ) { switch ( optChar ) { case 'h' : apr_file_printf ( out , \"Read option h ... \\n \" ); break ; case 'c' : apr_file_printf ( out , \"Read option c with argument %s \\n \" , optArg ); break ; default : apr_file_printf ( out , \"Default reached ... \\n \" ); } } if ( APR_STATUS_IS_BADCH ( rv )) { apr_file_printf ( err , \"Read bad option ... \\n \" ); } processedOptions = cmdLineArgs -> ind ; /* Now spit out non options */ while ( processedOptions < argc ) { apr_file_printf ( out , \"Non opt arg: %s \\n \" , cmdLineArgs -> argv [ processedOptions ++ ]); } apr_pool_destroy ( p ); return 0 ; } Now that you have seen how it works with simple options, long options is no more magic. You just have to additionally initialize an array basically, but see for yourself. Long options code #include <apr.h> #include <apr_file_io.h> #include <apr_getopt.h> /* Compile with * $> export APR_LIBS=\"`apr-1-config --cflags --cppflags --includes --ldflags --link-ld --libs`\" * $> export APU_LIBS=\"`apu-1-config --includes --ldflags --link-ld --libs`\" * $> gcc $APR_LIBS $APU_LIBS aprGetoptLong.c -o aprGetoptLong */ int main ( int argc , const char * const * argv ) { apr_pool_t * p = NULL ; apr_getopt_t * cmdLineArgs = NULL ; apr_status_t rv ; int optChar = 0 ; const char * optArg = NULL ; /* Will hold the position for the non optional * args in the APR parsed argv */ int processedOptions = 0 ; /* cleanly handle fileIO this time */ apr_file_t * out = NULL ; apr_file_t * err = NULL ; /* Let's handle long opts too */ const apr_getopt_option_t longOpts [] = {{ \"help\" , 'h' , 0 , \"Show help\" }, { \"choose\" , 'c' , 1 , \"Choose something\" }}; /* init APR, create memory pool */ apr_initialize (); atexit ( apr_terminate ); apr_pool_create ( & p , NULL ); /* Open stdin, stderr */ apr_file_open_stdout ( & out , p ); apr_file_open_stderr ( & err , p ); /* init APRs getopt */ apr_getopt_init ( & cmdLineArgs , p , argc , argv ); /* Allow options to be added after arguments */ cmdLineArgs -> interleave = 1 ; /* Now step through the options given */ while (( rv = apr_getopt_long ( cmdLineArgs , longOpts , & optChar , & optArg )) == APR_SUCCESS ) { switch ( optChar ) { case 'h' : apr_file_printf ( out , \"Read option h ... \\n \" ); break ; case 'c' : apr_file_printf ( out , \"Read option c with argument %s \\n \" , optArg ); break ; default : apr_file_printf ( out , \"Default reached ... \\n \" ); } } if ( APR_STATUS_IS_BADCH ( rv )) { apr_file_printf ( err , \"Read bad option ... \\n \" ); } processedOptions = cmdLineArgs -> ind ; /* Now spit out non options */ while ( processedOptions < argc ) { apr_file_printf ( out , \"Non opt arg: %s \\n \" , cmdLineArgs -> argv [ processedOptions ++ ]); } apr_pool_destroy ( p ); return 0 ; } Hope you enjoyed it. Downloads aprGetopt.c aprGetoptLong.c","tags":"Programming","url":"https://datapile.coffeecrew.org/programming-with-the-apr-using-apr_getopt","loc":"https://datapile.coffeecrew.org/programming-with-the-apr-using-apr_getopt"},{"title":"Programming with the APR - Persisting information","text":"This article will show you how to store information in the database that comes with the Apache Portable Runtime ( APR ). Basically a simple struct data type is persisted into that database. You can download the code here . Note The program supplied should actually use apr_app_initialize(&argc, &argv, NULL); since apr_initialize() is intended for library use only. Function description In order to store the information in that database you probably might want to create some functions to better break down work into smaller parts. Since the database mechanism requires you to have information available as an apr_datum_t type, you probably want to introduce some helper functions which exactly deal with that issue. Converting your normal data types into a apr_datum_t . Helper functions My helper functions which convert a normal char* or an apr_time_t into the required apr_datum_t are called: string2datum(apr_pool_t *p, char *toDatum) time2datum(apr_pool_t *p, apr_time_t *toDump) checkError(apr_status_t rv) You eventually might ask what the pool is for. Since the apr_datum_t type holds a char * and the according size of that pointer, we have to allocate space somewhere. That space is allocated on the pool you give that function. So make sure your pools lifetime is big enough so you can retrieve the value the function built for you. The checkError function is used for checking the return value that the various database access functions might return. This is basically to avoid lots of typing. Worker functions Now you need a few functions that do the actual work for you. APRs abstraction is not bad, but cannot handle automatic key generation in this case. APR uses a key for every saved apr_datum_t . We want to store a more complex datatype to disc, so we need to have a key for every field of our structure when we do want to save it. The basic idea is to flatten the structure when storing it. So we are writing every field of the structure linearly to disc. When we read the data from disc we do that in the same order as we have written it. This mechanism should restore the original data structure we were working with. The following functions persist a single datum, a whole struct and the read function reads back the whole struct from the disc. apr_status_t persistUserRecord(unsigned int *key, apr_dbm_t *database, struct userRecord *user) apr_status_t persistDatum(unsigned int *key, apr_dbm_t *database, apr_datum_t *toDump) struct userRecord *readUserRecord(apr_pool_t *resultPool, apr_dbm_t *db, apr_datum_t *lastReadKey) These functions are not implemented, but might give you an idea of how the API can look like if you want to serialize a whole bunch of data. void persistUserRecords(apr_table_t *userRecords) apr_table_t *readUserRecords(apr_pool_t *resultPool) You surely are interested in how the actual code looks by now. Now i will no longer deprive you from that. #include <apr.h> #include <apu.h> #include <apr_dbm.h> #include <apr_time.h> #include <apr_strings.h> #define APR_WANT_STDIO #define APR_WANT_MEMFUNC #include <apr_want.h> #define DBM_TYPE \"SDBM\" #define DEBUG #ifdef DEBUG #define PDEBUG(message, arguments) printf(\"[DEBUG] \" message \"\\n\", arguments) #define PDEBUG_NA(message) printf(\"[DEBUG] \" message \"\\n\") #else #define PDEBUG(message, arguments) /* empty */ #define PDEBUG_NA(message) /* empty */ #endif /* Compile with * $> export APR_LIBS=\"`apr-1-config --cflags --cppflags --includes --ldflags --link-ld --libs`\" * $> export APU_LIBS=\"`apu-1-config --includes --ldflags --link-ld --libs`\" * $> gcc $APR_LIBS $APU_LIBS aprWithSdbm.c -o aprWithSdbm */ struct userRecord { apr_time_t creationDate ; char * username ; char * password ; }; void print ( struct userRecord * user ); /* since apr_datum_t* results in a nested structure * this allocates the memory on the nested * char* onto the given pool. */ apr_datum_t * string2datum ( apr_pool_t * p , char * toDatum ); apr_datum_t * time2datum ( apr_pool_t * p , apr_time_t * toDatum ); apr_status_t persistDatum ( unsigned int * key , apr_dbm_t * database , apr_datum_t * toDump ); apr_status_t persistUserRecord ( unsigned int * key , apr_dbm_t * database , struct userRecord * user ); void persistUserRecords ( apr_table_t * userRecords ); struct userRecord * readUserRecord ( apr_pool_t * resultPool , apr_dbm_t * db , apr_datum_t * lastReadKey ); apr_table_t * readUserRecords ( apr_pool_t * resultPool ); void checkError ( apr_status_t rv ); int main ( int argc , char ** argv ) { struct userRecord * user , * user2 = NULL ; struct userRecord * userReadBack , * userReadBack2 = NULL ; apr_pool_t * mainPool = NULL ; apr_dbm_t * db ; unsigned int counter = 0 ; apr_datum_t readKey ; apr_status_t rv ; /* Always init at program start */ apr_initialize (); /* Register cleanup */ atexit ( apr_terminate ); /* create our main memory pool, * which will be valid during the programs lifetime */ apr_pool_create ( & mainPool , NULL ); /* Allocate memory for a user on the main pool */ user = apr_palloc ( mainPool , sizeof ( struct userRecord )); user -> username = apr_pstrdup ( mainPool , \"Jens Frey\" ); user -> password = apr_pstrdup ( mainPool , \"secret\" ); user -> creationDate = apr_time_now (); user2 = apr_palloc ( mainPool , sizeof ( struct userRecord )); user2 -> username = apr_pstrdup ( mainPool , \"Master Frey\" ); user2 -> password = apr_pstrdup ( mainPool , \"more secret password\" ); user2 -> creationDate = apr_time_now (); print ( user ); print ( user2 ); apr_dbm_open_ex ( & db , DBM_TYPE , \"/tmp/testDatabase\" , APR_DBM_RWTRUNC , APR_FPROT_OS_DEFAULT , mainPool ); PDEBUG ( \"Counter value: %u\" , counter ); persistUserRecord ( & counter , db , user ); persistUserRecord ( & counter , db , user2 ); PDEBUG ( \"Counter value: %u\" , counter ); //Query the first Key, the rest are subsequently queried alone rv = apr_dbm_firstkey ( db , & readKey ); checkError ( rv ); userReadBack = readUserRecord ( mainPool , db , & readKey ); userReadBack2 = readUserRecord ( mainPool , db , & readKey ); print ( userReadBack ); print ( userReadBack2 ); apr_dbm_close ( db ); apr_pool_destroy ( mainPool ); return 0 ; } void checkError ( apr_status_t rv ) { if ( rv != APR_SUCCESS ) { printf ( \"An error happened while operating with the database (code %d) \\n \" , rv ); } } struct userRecord * readUserRecord ( apr_pool_t * p , apr_dbm_t * db , apr_datum_t * lastReadKey ) { apr_datum_t tmp ; apr_status_t rv ; struct userRecord * user = apr_palloc ( p , sizeof ( struct userRecord )); PDEBUG_NA ( \"enter readUserRecord()\" ); /* Read username */ rv = apr_dbm_fetch ( db , * lastReadKey , & tmp ); checkError ( rv ); user -> username = apr_pstrndup ( p , tmp . dptr , tmp . dsize ); /* Advance to next key and read password */ rv = apr_dbm_nextkey ( db , lastReadKey ); checkError ( rv ); rv = apr_dbm_fetch ( db , * lastReadKey , & tmp ); checkError ( rv ); user -> password = apr_pstrndup ( p , tmp . dptr , tmp . dsize ); /* Timestamp */ rv = apr_dbm_nextkey ( db , lastReadKey ); checkError ( rv ); rv = apr_dbm_fetch ( db , * lastReadKey , & tmp ); checkError ( rv ); /* Memcpy that, that part of the structure is already alloced */ memcpy ( & user -> creationDate , tmp . dptr , sizeof ( apr_time_t )); /* Set the key to the next element, so a subsequent call will be correct again */ rv = apr_dbm_nextkey ( db , lastReadKey ); checkError ( rv ); PDEBUG_NA ( \"leave readUserRecord()\" ); return user ; } /* Converts an apr_time_t into a * persistable apr_datum_t */ apr_datum_t * time2datum ( apr_pool_t * p , apr_time_t * toDatum ) { apr_size_t size = 0 ; apr_datum_t * dt = apr_palloc ( p , sizeof ( apr_datum_t )); size = sizeof ( apr_time_t ); dt -> dptr = apr_pmemdup ( p , toDatum , size ); dt -> dsize = size ; return dt ; } /* * Converts the given char* into a apr_datum_t with lengths set correctly * depending on the database type. The memory required for the string * to be held is saved in the given memory pool. * */ apr_datum_t * string2datum ( apr_pool_t * p , char * toDatum ) { apr_datum_t * dt = apr_palloc ( p , sizeof ( apr_datum_t )); dt -> dptr = apr_pstrdup ( p , toDatum ); #ifndef NETSCAPE_DBM_COMPAT dt -> dsize = strlen ( dt -> dptr ); #else dt -> dsize = strlen ( dt -> dptr ) + 1 ; #endif return dt ; } /* This function persists the whole struct userRecord * into the SDBM database. You have to check if this implementation * is still correct if you change your struct. * * There should however be no problem if you are just adding transient * parameters that should not be persisted at all. */ apr_status_t persistUserRecord ( unsigned int * key , apr_dbm_t * database , struct userRecord * user ) { apr_status_t rv ; apr_datum_t * dumpKey ; apr_pool_t * p ; PDEBUG_NA ( \"enter persistUserRecord()\" ); apr_pool_create ( & p , NULL ); /* Now fill in every field of the record */ dumpKey = string2datum ( p , user -> username ); persistDatum ( key , database , dumpKey ); dumpKey = string2datum ( p , user -> password ); persistDatum ( key , database , dumpKey ); dumpKey = time2datum ( p , & user -> creationDate ); persistDatum ( key , database , dumpKey ); apr_pool_destroy ( p ); PDEBUG_NA ( \"leave persistUserRecord()\" ); return rv ; } /* Assumes an open database. */ apr_status_t persistDatum ( unsigned int * key , apr_dbm_t * database , apr_datum_t * toDump ) { apr_status_t rv ; apr_datum_t datumKey ; datumKey . dptr = ( char * ) key ; datumKey . dsize = sizeof ( unsigned int ); PDEBUG_NA ( \"enter persistDatum()\" ); rv = apr_dbm_store ( database , datumKey , * toDump ); if ( rv != APR_SUCCESS ) { printf ( \"Error saving datum in database (returned %d)\" , rv ); } //Increment count for every written datum ( * key ) ++ ; PDEBUG ( \"Key is %u\" , * key ); PDEBUG_NA ( \"leave persistDatum()\" ); return rv ; } void print ( struct userRecord * user ) { apr_pool_t * p = NULL ; char * timeReadable = NULL ; apr_pool_create ( & p , NULL ); timeReadable = apr_palloc ( p , APR_RFC822_DATE_LEN ); apr_rfc822_date ( timeReadable , user -> creationDate ); PDEBUG ( \"Username: %s\" , user -> username ); PDEBUG ( \"Password: %s\" , user -> password ); PDEBUG ( \"CreationDate (long): %\" APR_TIME_T_FMT , user -> creationDate ); PDEBUG ( \"CreationDate (read): %s\" , timeReadable ); apr_pool_destroy ( p ); } Hope you enjoyed it.","tags":"Programming","url":"https://datapile.coffeecrew.org/programming-with-the-apr-persisting-information","loc":"https://datapile.coffeecrew.org/programming-with-the-apr-persisting-information"},{"title":"Programming with the APR","text":"This article will give you an introduction of how to program with the Apache Portable Runtime ( APR ). It illustrates a simple command line program. Note The program supplied should actually use apr_app_initialize(&argc, &argv, NULL); since apr_initialize() is intended for library use only. I was playing around with the Apache Portable Runtime ( APR ) recently and found out, probably the most difficult part was to find out how to compile the program you have just written. The probably most famous projects using APR are the Apache HTTPd and Subversion. Overview APR 's goal is to provide a platform independent API that provides a consistent interface to the platform specific implementation. The APR code itself is pretty good documented. But i wouldn't say you'd find plenty of resources on the web. Especially a simple example on how to program with the APR was missing for me. Example program I put together an example program which shows how to use the APR . This includes instructions on how to get the program compiled after you have written it. This seems to be so self-evident to people, that no one seems to write that up. The heart of this process lies in the usage of the apr-config , or sometimes called apr-1-config utility. Preconditions Make sure you have the APR development files installed. Since i am mostly working with Debian based distributions, like Debian itself or Ubuntu, i install the libraries with my package management system. Of course make sure you install the \"-dev\" versions of APR . For me that have been the packages libapr1 libapr1-dbg libapr1-dev libaprutil1 libaprutil1-dbg libaprutil1-dev You can get those packages by issuing the following command on the command line (this may of course vary if you are not using a Debian based distribution or if you install from source): $ sudo apt-get install libapr1 libapr1-dbg libapr1-dev libaprutil1 libaprutil1-dbg libaprutil1-dev Program code The program itself is obviously a pretty easy one, it basically allocates resources from a memory pool managed through APR onto a struct and later simply prints the allocated values. The programs code is as follows. Compile the program Now there comes the next crucial step in getting your program to fly. To do so you probably best export a variable as suggested by the apr-1-config tool. Then you can go on an compile your program the \"normal\" way you'd do that. If you do not want debug symbols compiled into your code, you of course would remove the -g option in front of the APR_LIBS variable: $> export APR_LIBS=\"`apr-1-config --cflags --cppflags --includes --ldflags --link-ld --libs`\" $> gcc -g simple_apr.c -o simple_apr $APR_LIBS By executing the program your output should now look something like that: $ ./simple_apr Username: Jens Frey Password: secret Time: 1231102877630911 Time readable: Sun, 04 Jan 2009 21:01:17 GMT I hope you achieved similar results. References The APR homepage The APR API documentation Using APR Pools Writing Portable C Code with APR","tags":"Programming","url":"https://datapile.coffeecrew.org/programming-with-the-apr","loc":"https://datapile.coffeecrew.org/programming-with-the-apr"},{"title":"Backing up roller weblogger","text":"If you followed the Setup Roller Weblogger 4.1 On Glassfish V2 tutorial, or you do have a roller installation already in place, you probably want to back that up somehow. Backup the file system Since I do not know where you possibly will have installed roller to, I am using the locations from the previous how to. The backup procedure should not be that complex after all. The data residing on your filesystem (I know, the database resides on the file system too), is the data you uploaded into you blog. You do have a /opt/roller/uploads directory for example. Depending on how many blogs you have created, there are numerous folders inside. Each sub-folder represents data for another blog. So if your blog is called \"datapile\", then there will be a \"datapile\" sub-folder. For the sake of simplicity you can of course just backup the whole /opt/roller folder which should also save the custom themes you created eventually. If you installed it the way as described in the tutorial at the beginning, you do also backup search indexes and the glassfish installation with this. Warning You might not have deleted the /opt/roller/tmp directory yet. You might backup this temporary files too in this case. If you backup the full /opt/roller directory, you might remove the /opt/roller/tmp folder manually, or at least move it to another location, so your compressed archive will not pack that (unnecessary) information too. A simple command line might look like as follows: $ cd /opt/ && tar cjvf /tmp/roller.tar.bz2 roller/ Restore the file system In order to restore the file system you have to recreate your installation and then copy the files back to the location where the installation can find them, or simply untar your backed up /opt/roller folder. Backup the database The database can be backed up pretty easily. The part to remember is that you switch to the postgres user when you execute the pg_dumpall > /tmp/rollerDb.dump command. The backup command order in this case is: root@sigusr1:$ # su - postgres $ pg_dumpall > /tmp/rollerDb.dump $ pg_dumpall | bzip2 > /tmp/rollerDb.dump.bz2 #bzipped version Restore the database Restoring the full database is a pretty easy task. On a test installation I did, this worked like a charm. I really hope there's nothing more to add to it. root@sigusr1:$ # su - postgres $ createdb rollerdb $ cat /tmp/rollerDb.dump.bz2 | bunzip2 | psql postgres $ psql -f /tmp/rollerDb.dump postgres #restore from non-compressed file After having played back the information into the database, you might need to adopt the postgres passwords back to the values you have set them during your installation on the servlet container (in this case glassfish). You might otherwise end up with some ugly exceptions. To do that start the psql tool as postgres user and enter the following statements (of course adopt to your password ;) ). postgres @ sigusr1 : ~ $ psql postgres =# alter user roller with password 'roller' ; postgres =# alter user postgres with password 'postgres' ; References Especially when it comes to handling the database stuff, the PostgreSQL documentation was very helpful. http://www.postgresql.org/docs/8.1/static/backup.html","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/backing-up-roller-weblogger","loc":"https://datapile.coffeecrew.org/backing-up-roller-weblogger"},{"title":"Switching roller from Derby to PostgreSQL","text":"Since Roller seems to have problems with the Glassfish built-in Derby database, especially when it comes to \"Full preview\" (you might end up with an HTTP 404 error code if you try to preview your post), you might want to switch your Roller installation to PostgreSQL . This article will explain, how you can switch the installed Roller instance from Glassfishs built-in derby database to the PostgreSQL database. Note This was implemented/tested with Roller Weblogger 4.1 and Glassfish v2UR2 Quick install For the people who don't care if anything goes wrong or just don't like to type at all, here is a little script , which might help you save a few keystrokes. Just be aware of the fact that you might have to change a few variables inside the script. Manual installation This describes basically what the script in the quick installation tries to achieve by being run. Prerequisites As with the roller install itself, you need of course a few things before you can start. In this case you need of course the PostgreSQL database itself and a JDBC driver to attach roller to the database. The installation of the database depends on the type of operating system you are using. I describe the setup using a Debian based system, since this is so nice and easy :). Get the database driver To enable Glassfish to talk to your postgres installation, you have to supply it some code. Glassfish likes Java the best and you can get some JDBC drivers from here , but specifically the postgresql-8.3-604.jdbc3.jar is of interest to us. So go get the JDBC driver and save it in /opt/roller/glassfish/domains/roller/lib Install database For a debian based system just enter the following command as user root (or prefix it with sudo on ubuntu). You might of course have a newer version of postgresql available with you current installation. root@sigusr1:$ aptitude install postgresql-8.1 After the installation finishes, you might want to create the database roller will be accessing later and also create a user for use with roller. This can be achieved by entering the following sequence of commands into a terminal of your choice. Note Be aware of the fact that you have to execute the commands as user postgres . root@sigusr1:$ # Get root su - # Get postgres user su - postgres # create database createdb rollerdb # create roller user createuser roller # Answers # Shall the new role be a superuser? (y/n) n # Shall the new role be allowed to create databases? (y/n) n # Shall the new role be allowed to create more new roles? (y/n) n # Enter postgres prompt psql When you are in the prompt which will look something like this: Welcome to psql 8 . 3 . 4 , the PostgreSQL interactive terminal . Type : \\ copyright for distribution terms \\ h for help with SQL commands \\ ? for help with psql commands \\ g or terminate with semicolon to execute query \\ q to quit postgres =# Enter the following SQL statements which change the passwords for the roller and postgres user accordingly: alter user roller with password 'roller' ; alter user postgres with password 'postgres' ; You are now finished using the postgres user. You may want to continue as user roller with the following commands. If you followed the Setup Roller Weblogger 4.1 On Glassfish V2 tutorial, you do have to do an additional step to get rid of the previously assigned JDBC connection; that is deleting the JDBC connection pool. Aside from that we simply create a JDBC connection pool and the according resource. Once that is done you might want to start configuring your roller installation. root@sigusr1:$ #if you followed glassfish ... (cleans jdbc resource too) ./bin/asadmin delete-jdbc-connection-pool --cascade rollerpool ./bin/asadmin create-jdbc-connection-pool --datasourceclassname org.postgresql.ds.PGSimpleDataSource \\ --restype javax.sql.DataSource \\ --property portNumber = 5432 :password = roller:user = roller:serverName = localhost:databaseName = rollerdb \\ rollerpool ./bin/asadmin ping-connection-pool rollerpool ./bin/asadmin create-jdbc-resource --connectionpoolid = rollerpool jdbc/rollerdb Once that is finished, you should restart Glassfish in order to make changes effective. This is done through the following command: root@sigusr1:$ su - roller -c \"cd glassfish; ./bin/asadmin stop-domain roller\" && \\ su - roller -c \"cd glassfish; ./bin/asadmin start-domain roller\" When you have finished all that, you now should be able to point you browser to http://localhost:8080/blogs and start configuring your Roller installation. Have fun.","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/switching-roller-from-derby-to-postgresql","loc":"https://datapile.coffeecrew.org/switching-roller-from-derby-to-postgresql"},{"title":"Free iPhone Ringtone #1","text":"I created a free drum and bassy iPhone ringtone, install it if you like :) Your browser does not support the audio element. Download iPhone Ringtone ( M4R ) Hope you have fun with it …","tags":"Music","url":"https://datapile.coffeecrew.org/free-iphone-ringtone-1","loc":"https://datapile.coffeecrew.org/free-iphone-ringtone-1"},{"title":"Setup roller weblogger 4.1 on Glassfish v2","text":"This guide will walk you through installing the Apache Roller Blog Software, version 4.1(-dev). The installation I did, resides on a Debian based distribution (Ubuntu works too, just prefix the commands with sudo). Note This was implemented/tested with Roller Weblogger 4.1 and Glassfish v2UR2 Quick install This is for the impatient, you need to have jar and wget in your $ PATH If you just want to have roller to be set up for you to do e.g. some work on roller templates, or just to basically play with it a bit, here is the real quick deal for you (This will install everything into /opt/roller). Download the automated installer script , save it to e.g. your home directory. Then call the script like ./rollerGlassfish.sh realLongKey1 realLongKey2 run-as-username run-as-groupname . Note You can get those long keys easily from GRC . Manual installation The following text basically describes what the script is automatically doing for you. This way you can change the according parameters which will affect your installation. Most probably you will just have to change the following variables inside the install script. Prerequisites You have to install a few things before you can actually start installing roller on your system. At first you need to be sure that the jar command is installed on your system, since this is required for the build you will be doing on your system. On a Debian based system you can do that with the following command: root@sigusr1:$ aptitude install sun-java5-jdk After the JDK installation you basically have everything ready to go, but wait if you want to use my automated installer script you need to have the wget command installed too, since the script tries to download the Glassfish application server and the given Apache Roller version by itself in order to be able to install it for you. root@sigusr1:$ # TARGET = /opt/roller TARGET_TMP = ${ TARGET } /tmp UPLOADS = $TARGET /uploads THEMES = $TARGET /themes PLANET_CACHE = $TARGET /planetcache SEARCH_INDEX = $TARGET /searchindex #ROLLER_FILENAME=\"apache-roller-4.0.1-snapshot-20080211.tar.gz\" ROLLER_FILENAME = \"apache-roller-4.1-snapshot-m1.tar.gz\" CTX_ROOT = \"blogs\" Gist: https://gist.github.com/authsec/455940a3f6bd5673c1c9dd16ea4ec0af Download Glassfish Choose install location As a last prerequisite step you need to choose an install location. I chose /opt/roller to be the install location of my choice. Setup user and group As you probably won't be running roller as root, you'll have to setup a user and a group for your roller installation. This, again on Debian based systems, is done using the following commands: root@sigusr1:$ mkdir /opt/roller addgroup --system roller adduser --home /opt/roller \\ --shell /bin/bash \\ --no-create-home \\ --ingroup roller \\ --disabled-password \\ --system roller Setup Glassfish I assume you downloaded roller and glassfish into /opt/roller/tmp . In order to get the Glassfish installation working, you need to have JAVA_HOME exported into your environment. Then you can start running the Glassfish installer. On a bourne shell do (inside the directory where you saved the Glassfish installer): root@sigusr1:$ cd /opt/roller/tmp export JAVA_HOME = /usr/lib/jvm/java-1.5.0-sun java -Xmx256m -jar glassfish-installer-v2ur2-b04-linux.jar The installer will ask you if you are willing to accept the license agreement. If you are running this on a remote machine, it will ask you on the command line, whether or not you are willing to accept; on your local machine it will show a nice graphical dialog for you to accept. After that setup is completed, do (machine name is included, so you're able to see in which directory I'm operating) j@sigusr1:/opt/roller/tmp$ mv glassfish .. j@sigusr1:/opt/roller/tmp$ cd ../glassfish/ j@sigusr1:/opt/roller/glassfish$ chmod -R +x lib/ant/bin As a next step you have to setup a domain for roller within Glassfish, this is a rather easy task to do: j@sigusr1:/opt/roller/glassfish$ lib/ant/bin/ant -f setup.xml -Ddomain.name = roller Now start Glassfish, so we can do s.th. with it … j@sigusr1:/opt/roller/glassfish$ ./bin/asadmin start-domain roller Setup built in database The following series of command all takes place inside the /opt/roller/glassfish directory. root@sigusr1:$ ./bin/asadmin create-jdbc-connection-pool \\ --datasourceclassname org.apache.derby.jdbc.EmbeddedDataSource \\ --property databaseName = \\$\\{ com.sun.aas.instanceRoot \\} /databases/rollerdb: \\ connectionAttributes = \\; create \\\\ = true rollerpool ./bin/asadmin ping-connection-pool rollerpool ./bin/asadmin create-jdbc-resource --connectionpoolid = rollerpool jdbc/rollerdb Setup JNDI mail resource If that would work in roller 4.1(-dev) with Glassfish, you would do: root@sigusr1:$ ./bin/asadmin create-javamail-resource --mailhost localhost --mailuser rollermail --fromaddress roller \\@ blogs \\. coffeecrew \\. org mail/Session Securing Glassfish Some of you might be thinking about running Glassfish behind an Apache reverse proxy. This is exactly what I am thinking about. So if you plan to do that, it might come in handy that Glassfish would only accept connections from the local machine and therefore not let anyone easily bypass your secured apache instance. First we delete both HTTP listener instances that are listening on ports 8080 and 8443 and then recreate the 8080 one. As we are proxying with apache, we do not need the SSL listener (port 8443) anyway. And while we're just doing it, let's rebind those IIOP services to. root@sigusr1:$ ./bin/asadmin delete-http-listener http-listener-1 ./bin/asadmin delete-http-listener http-listener-2 ./bin/asadmin create-http-listener --listeneraddress 127 .0.0.1 --listenerport 8080 --acceptorthreads 32 --enabled = true --defaultvs server --securityenabled = false roller-listener # Configure admin page to listen locally too ./bin/asadmin set server.http-service.http-listener.admin-listener.address = 127 .0.0.1 # Disable IIOP stuff to listen globally, we do not need that right now. ./bin/asadmin set server.iiop-service.iiop-listener.SSL.address = 127 .0.0.1 ./bin/asadmin set server.iiop-service.iiop-listener.SSL_MUTUALAUTH.address = 127 .0.0.1 ./bin/asadmin set server.iiop-service.iiop-listener.orb-listener-1.address = 127 .0.0.1 # Disable JMX connector for remote access ./bin/asadmin set server.admin-service.jmx-connector.system.enabled = false # JMS ./bin/asadmin set server.jms-service.jms-host.default_JMS_host.host = localhost # Require client authentication, just to be sure ... ./bin/asadmin set server.iiop-service.client-authentication-required = true Now, to make changes effective we have to restart Glassfish. But before that we want to make sure everything has correct permissions for our newly created user, won't we? root@sigusr1:$ # Fix permissions chown -R roller:roller /opt/roller # Restart gf to make changes effective ./bin/asadmin stop-domain roller # Start as roller user su -c \"./bin/asadmin start-domain roller\" roller Setup and configure Roller Setting up Roller 4.1(-dev) is pretty easy. We start by extracting the tarball we downloaded earlier. Since we have set our theme directory to be /opt/roller/themes we do have to copy the themes we want to use there. As a next step we really want to have security keys **changed** . This is done by either editing the security.xml file manually or using a sed expression. After we have changed the keys, we can pack us a nice roller.war file. The few commands below execute the described actions. root@sigusr1:$ #Roller setup cd /opt/roller/tmp tar zxvf apache-roller-4.1-snapshot-m1.tar.gz #Copy themes cd apache-roller*/webapp/roller/themes cp -vR * /opt/roller/themes cd ../WEB-INF cp security.xml /tmp # actually change keys cat /tmp/security.xml | \\ sed \"s/name=\\\"key\\\" value=\\\"anonymous\\\"/name=\\\"key\\\" value=\\\"myOwnLongKey\\\"/\" | \\ sed \"s/name=\\\"key\\\" value=\\\"rollerlovesacegi\\\"/name=\\\"key\\\" value=\\\"myOwnLongKey2\\\"/\" \\ > security.xml #Pack war file cd .. jar cvf ../../../roller.war * Now we're nearly finished … just a few seconds away from experimenting with your own roller instance now :). As a next necessary step we need to create a custom configuration file for Roller. That configuration file has to be saved in /opt/roller/glassfish/domains/roller/lib/classes/roller-custom.properties to take effect. The configuration file can be built as follows: root@sigusr1:$ #Build roller-custom.properties cat <<EOF > $TARGET/glassfish/domains/roller/lib/classes/roller-custom.properties installation.type=auto #Should work with JNDI but maybe not with glassfish mail.configurationType=properties mail.hostname=localhost planet.aggregator.enabled=true uploads.dir=$UPLOADS themes.dir=$THEMES search.index.dir=$SEARCH_INDEX planet.aggregator.cache.dir=$PLANET_CACHE EOF Now that the configuration is in place, we are finally ready to deploy the Roller application. With the deployment we are able to specify a context root, which is the ( URL ) location where your application can be reached later on. So if you specify blogs then your application can later be accessed at http://your.example.com:8080/blogs . root@sigusr1:$ #Deploy application cd $TARGET /glassfish ./bin/asadmin deploy --contextroot blogs ../tmp/roller.war Just to be sure everything you've installed so far has correct permission, you might want to run the following commands again. It fixes your permissions and runs Glassfish as roller user. root@sigusr1:$ # Fix permissions chown -R roller:roller /opt/roller #Restart gf to make changes effective ./bin/asadmin stop-domain roller # Start as roller user su -c \"./bin/asadmin start-domain roller\" roller After you've done all that you now should have a ready to go roller installation. Now go visit http://localhost:8080/blogs and configure your shiny new roller installation. It is pretty much self explanatory, but if you need further assistance, you might want to have a look into the installation guide, which you can get here (see chapter 8ff). Now after you've set up everything exactly as you like, you should change /opt/roller/glassfish/domains/roller/lib/classes/roller-custom.properties to read installation.type=manual","tags":"Infrastructure","url":"https://datapile.coffeecrew.org/setup-roller-weblogger-41-on-glassfish-v2","loc":"https://datapile.coffeecrew.org/setup-roller-weblogger-41-on-glassfish-v2"}]};